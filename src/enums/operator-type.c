// Copyright 2022 Google LLC
//
// This source code is licensed under the BSD-style license found in the
// LICENSE file in the root directory of this source tree.
//
// Auto-generated file. Do not edit!
//   Specification: src/enums/operator-type.yaml
//   Generator: tools/generate-enum.py

#include <assert.h>
#include <stdint.h>

#include "xnnpack/operator-type.h"

static const uint16_t offset[172] = {
  0, 8, 22, 36, 50, 64, 78, 92, 106, 133, 161, 189, 217, 244, 271, 303, 335, 378, 396, 414, 439, 465, 481, 497, 512,
  527, 549, 572, 595, 618, 641, 664, 687, 710, 733, 756, 774, 797, 820, 844, 862, 885, 909, 933, 957, 981, 1016, 1051,
  1075, 1099, 1123, 1137, 1152, 1167, 1187, 1213, 1239, 1276, 1302, 1332, 1358, 1390, 1422, 1448, 1475, 1502, 1519,
  1536, 1570, 1604, 1618, 1632, 1646, 1660, 1676, 1692, 1718, 1744, 1776, 1808, 1845, 1882, 1919, 1956, 1993, 2030,
  2067, 2093, 2125, 2151, 2166, 2200, 2234, 2268, 2302, 2336, 2370, 2400, 2430, 2450, 2470, 2491, 2512, 2533, 2554,
  2568, 2592, 2616, 2639, 2662, 2680, 2698, 2713, 2728, 2746, 2764, 2783, 2802, 2821, 2840, 2859, 2876, 2893, 2906,
  2922, 2938, 2971, 3004, 3032, 3060, 3088, 3116, 3143, 3170, 3187, 3204, 3245, 3286, 3304, 3322, 3340, 3358, 3373,
  3389, 3405, 3423, 3441, 3459, 3485, 3512, 3539, 3556, 3573, 3595, 3617, 3646, 3675, 3694, 3713, 3732, 3751, 3766,
  3781, 3796, 3811, 3830, 3850, 3870, 3890, 3911, 3932, 3954
};

static const char data[] =
  "Invalid\0"
  "Abs (NC, F16)\0"
  "Abs (NC, F32)\0"
  "Add (ND, F16)\0"
  "Add (ND, F32)\0"
  "Add (ND, QS8)\0"
  "Add (ND, QU8)\0"
  "AND (ND, S32)\0"
  "ArgMax Pooling (NHWC, F32)\0"
  "Average Pooling (NHWC, F16)\0"
  "Average Pooling (NHWC, F32)\0"
  "Average Pooling (NHWC, QU8)\0"
  "Bankers Rounding (NC, F16)\0"
  "Bankers Rounding (NC, F32)\0"
  "Batch Matrix Multiply (NC, F16)\0"
  "Batch Matrix Multiply (NC, F32)\0"
  "Batch Matrix Multiply (NC, QD8, F32, QC8W)\0"
  "Ceiling (NC, F16)\0"
  "Ceiling (NC, F32)\0"
  "Channel Shuffle (NC, X8)\0"
  "Channel Shuffle (NC, X32)\0"
  "Clamp (NC, F16)\0"
  "Clamp (NC, F32)\0"
  "Clamp (NC, S8)\0"
  "Clamp (NC, U8)\0"
  "Constant Pad (ND, X8)\0"
  "Constant Pad (ND, X16)\0"
  "Constant Pad (ND, X32)\0"
  "Convert (NC, F16, F32)\0"
  "Convert (NC, F16, QD8)\0"
  "Convert (NC, F32, F16)\0"
  "Convert (NC, F32, QD8)\0"
  "Convert (NC, F32, QP8)\0"
  "Convert (NC, F32, QS8)\0"
  "Convert (NC, F32, QU8)\0"
  "Convert (NC, QS8)\0"
  "Convert (NC, QS8, F16)\0"
  "Convert (NC, QS8, F32)\0"
  "Convert (NC, QS16, QS8)\0"
  "Convert (NC, QU8)\0"
  "Convert (NC, QU8, F32)\0"
  "Convolution (NCHW, F16)\0"
  "Convolution (NCHW, F32)\0"
  "Convolution (NHWC, F16)\0"
  "Convolution (NHWC, F32)\0"
  "Convolution (NHWC, QD8, F16, QC8W)\0"
  "Convolution (NHWC, QD8, F32, QC8W)\0"
  "Convolution (NHWC, QC8)\0"
  "Convolution (NHWC, QS8)\0"
  "Convolution (NHWC, QU8)\0"
  "Copy (NC, X8)\0"
  "Copy (NC, X16)\0"
  "Copy (NC, X32)\0"
  "Copy Sign (NC, F32)\0"
  "Deconvolution (NHWC, F16)\0"
  "Deconvolution (NHWC, F32)\0"
  "Deconvolution (NHWC, QD8, F32, QC8W)\0"
  "Deconvolution (NHWC, QS8)\0"
  "Deconvolution (NC, QS8, QC8W)\0"
  "Deconvolution (NHWC, QU8)\0"
  "Depth To Space (NCHW2NHWC, X16)\0"
  "Depth To Space (NCHW2NHWC, X32)\0"
  "Depth To Space (NHWC, X8)\0"
  "Depth To Space (NHWC, X16)\0"
  "Depth To Space (NHWC, X32)\0"
  "Divide (ND, F16)\0"
  "Divide (ND, F32)\0"
  "Dynamic Fully Connected (NC, F16)\0"
  "Dynamic Fully Connected (NC, F32)\0"
  "ELU (NC, F16)\0"
  "ELU (NC, F32)\0"
  "ELU (NC, QS8)\0"
  "Exp (NC, F32)\0"
  "Floor (NC, F16)\0"
  "Floor (NC, F32)\0"
  "Fully Connected (NC, F16)\0"
  "Fully Connected (NC, F32)\0"
  "Fully Connected (NC, F32, QC4W)\0"
  "Fully Connected (NC, F32, QC8W)\0"
  "Fully Connected (NC, QD8, F16, QB4W)\0"
  "Fully Connected (NC, QD8, F16, QC4W)\0"
  "Fully Connected (NC, QD8, F16, QC8W)\0"
  "Fully Connected (NC, QD8, F32, QB4W)\0"
  "Fully Connected (NC, QD8, F32, QC4W)\0"
  "Fully Connected (NC, QD8, F32, QC8W)\0"
  "Fully Connected (NC, QP8, F32, QC4W)\0"
  "Fully Connected (NC, QS8)\0"
  "Fully Connected (NC, QS8, QC8W)\0"
  "Fully Connected (NC, QU8)\0"
  "GELU (NC, F32)\0"
  "Global Average Pooling (NCW, F16)\0"
  "Global Average Pooling (NCW, F32)\0"
  "Global Average Pooling (NWC, F16)\0"
  "Global Average Pooling (NWC, F32)\0"
  "Global Average Pooling (NWC, QS8)\0"
  "Global Average Pooling (NWC, QU8)\0"
  "Global Sum Pooling (NWC, F16)\0"
  "Global Sum Pooling (NWC, F32)\0"
  "HardSwish (NC, F16)\0"
  "HardSwish (NC, F32)\0"
  "Leaky ReLU (NC, F16)\0"
  "Leaky ReLU (NC, F32)\0"
  "Leaky ReLU (NC, QS8)\0"
  "Leaky ReLU (NC, QU8)\0"
  "Log (NC, F32)\0"
  "Max Pooling (NHWC, F16)\0"
  "Max Pooling (NHWC, F32)\0"
  "Max Pooling (NHWC, S8)\0"
  "Max Pooling (NHWC, U8)\0"
  "Maximum (ND, F16)\0"
  "Maximum (ND, F32)\0"
  "Mean (ND, F16)\0"
  "Mean (ND, F32)\0"
  "Minimum (ND, F16)\0"
  "Minimum (ND, F32)\0"
  "Multiply (ND, F16)\0"
  "Multiply (ND, F32)\0"
  "Multiply (ND, QS8)\0"
  "Multiply (ND, QU8)\0"
  "Multiply (ND, S32)\0"
  "Negate (NC, F16)\0"
  "Negate (NC, F32)\0"
  "OR (ND, S32)\0"
  "PReLU (NC, F16)\0"
  "PReLU (NC, F32)\0"
  "Reciprocal Square Root (NC, F16)\0"
  "Reciprocal Square Root (NC, F32)\0"
  "Resize Bilinear (NCHW, F16)\0"
  "Resize Bilinear (NCHW, F32)\0"
  "Resize Bilinear (NHWC, F16)\0"
  "Resize Bilinear (NHWC, F32)\0"
  "Resize Bilinear (NHWC, S8)\0"
  "Resize Bilinear (NHWC, U8)\0"
  "RoPE (NTHC, F16)\0"
  "RoPE (NTHC, F32)\0"
  "Scaled Dot-Product Attention (NHTC, F16)\0"
  "Scaled Dot-Product Attention (NHTC, F32)\0"
  "Sigmoid (NC, F16)\0"
  "Sigmoid (NC, F32)\0"
  "Sigmoid (NC, QS8)\0"
  "Sigmoid (NC, QU8)\0"
  "Slice (ND, X8)\0"
  "Slice (ND, X16)\0"
  "Slice (ND, X32)\0"
  "Softmax (NC, F16)\0"
  "Softmax (NC, F32)\0"
  "Softmax (NC, QU8)\0"
  "Space To Depth (NHWC, X8)\0"
  "Space To Depth (NHWC, X16)\0"
  "Space To Depth (NHWC, X32)\0"
  "Square (NC, F16)\0"
  "Square (NC, F32)\0"
  "Square Root (NC, F16)\0"
  "Square Root (NC, F32)\0"
  "Squared Difference (NC, F16)\0"
  "Squared Difference (NC, F32)\0"
  "Subtract (ND, F16)\0"
  "Subtract (ND, F32)\0"
  "Subtract (ND, QS8)\0"
  "Subtract (ND, QU8)\0"
  "Tanh (NC, F16)\0"
  "Tanh (NC, F32)\0"
  "Tanh (NC, QS8)\0"
  "Tanh (NC, QU8)\0"
  "Transpose (ND, X8)\0"
  "Transpose (ND, X16)\0"
  "Transpose (ND, X32)\0"
  "Transpose (ND, X64)\0"
  "Truncation (NC, F16)\0"
  "Truncation (NC, F32)\0"
  "Unpooling (NHWC, X32)\0"
  "XOR (ND, S32)";

const char* xnn_operator_type_to_string(enum xnn_operator_type operator_type) {
  assert(operator_type >= xnn_operator_type_invalid);
  assert(operator_type <= xnn_operator_type_xor_nd_s32);
  return &data[offset[operator_type]];
}
