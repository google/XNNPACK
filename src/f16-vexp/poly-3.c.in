// Copyright 2025 Google LLC
//
// This source code is licensed under the BSD-style license found in the
// LICENSE file in the root directory of this source tree.

$BATCH_TILES = tuple(int(bt) for bt in BATCH_TILES.split(","))
$SIMD_SIZE = BATCH_TILES[0]
#include <assert.h>
#include <stddef.h>
#include <stdint.h>

#include "src/xnnpack/simd/f16-${ARCH}.h"

#include "src/xnnpack/common.h"
#include "src/xnnpack/math.h"
#include "src/xnnpack/microparams.h"


static XNN_INLINE xnn_simd_f16_t xnn_setexp_f16(xnn_simd_f16_t vx) {
  // If `x` is an xnn_float16ing point value in the range [-15, 16], then
  // `(x + magic) << 10` will generate the floating point value corresponding
  // to `2^round(x)` (2^-15 and 2^16 will flush to zero and infinity,
  // respectively).
  XNN_SIMD_CONST_F16_FROM_FLOAT(vmagic, 1039.0f);  // 2^10 + 15.
  return xnn_sll_f16(xnn_add_f16(vx, vmagic), 10);
}

// Quick-and-dirty round to nearest, only works for xnn_float16s in the range
// `[2^-9, 2^9)`.
static XNN_INLINE xnn_simd_f16_t xnn_qd_round_f16(xnn_simd_f16_t vx) {
  // If `x` is an xnn_float16ing point value in the range `[2^-9, 2^9)`, then
  // `(x + magic) - magic`` will generate the floating point value corresponding
  // to `round(x)`.
  XNN_SIMD_CONST_F16_FROM_FLOAT(vmagic, 1536.0f);  // 2^10 + 2^9.
  return xnn_sub_f16(xnn_add_f16(vmagic, vx), vmagic);
}

$for BATCH_TILE in BATCH_TILES:
  $assert BATCH_TILE % SIMD_SIZE == 0
  $assert BATCH_TILE >= SIMD_SIZE
  $SIMD_TILE = BATCH_TILE // SIMD_SIZE
  void xnn_f16_vexp_ukernel__${ARCH}_poly_3_u${BATCH_TILE}(
      size_t batch,
      const xnn_float16* input,
      xnn_float16* output,
      const struct xnn_f16_default_params unused_params[restrict XNN_MIN_ELEMENTS(1)])
  {
    assert(batch != 0);
    assert(batch % sizeof(xnn_float16) == 0);
    assert(input != NULL);
    assert(output != NULL);
    assert(xnn_simd_size_f16 == ${SIMD_SIZE});

    // The monomial coefficients of the interpolation polynomial (`valpha_0` = 1).
    XNN_SIMD_CONST_F16_FROM_FLOAT(valpha_1, 0.6933594f);
    XNN_SIMD_CONST_F16_FROM_FLOAT(valpha_2, 0.24255371f);
    XNN_SIMD_CONST_F16_FROM_FLOAT(valpha_3, 0.05517578f);
        
    // Some useful constants.
    XNN_SIMD_CONST_F16_FROM_FLOAT(vlog2e, 1.4423828f);
    XNN_SIMD_CONST_F16_FROM_FLOAT(v16, 16.0f);
    XNN_SIMD_CONST_F16_FROM_FLOAT(vm15, -15.0f);
    XNN_SIMD_CONST_F16_FROM_FLOAT(vone, 1.0f);

    $if SIMD_TILE > 1:
      for (; batch >= ${BATCH_TILE} * sizeof(xnn_float16); batch -= ${BATCH_TILE} * sizeof(xnn_float16)) {
        $for N in range(SIMD_TILE):
          xnn_simd_f16_t vx_${N} = xnn_loadu_f16(input + ${N} * xnn_simd_size_f16);
        input += ${BATCH_TILE};
        
        // Clamp `vz_prime = x * log2(e)` to the maximum exponents [-127, 128].
        $for N in range(0, SIMD_TILE):
          xnn_simd_f16_t vz_prime_${N} = xnn_mul_f16(vx_${N}, vlog2e);
        $for N in range(0, SIMD_TILE):
          vz_prime_${N} = xnn_min_f16(xnn_max_f16(vz_prime_${N}, vm15), v16);

        // Decompose x * log2e into `z` (integer part) and `r` (remainder).
        $for N in range(0, SIMD_TILE):
          const xnn_simd_f16_t vz_${N} = xnn_qd_round_f16(vz_prime_${N});
        $for N in range(0, SIMD_TILE):
          const xnn_simd_f16_t vr_${N} = xnn_sub_f16(vz_prime_${N}, vz_${N});
        
        // Compute 2^z.
        $for N in range(0, SIMD_TILE):
          const xnn_simd_f16_t v2z_${N} = xnn_setexp_f16(vz_${N});

        // Evaluate the interpolation polynomial for `2^r`.
        $for N in range(0, SIMD_TILE):
          xnn_simd_f16_t v2r_${N} = xnn_fmadd_f16(vr_${N}, valpha_3, valpha_2);
        $for N in range(0, SIMD_TILE):
          v2r_${N} = xnn_fmadd_f16(vr_${N}, v2r_${N}, valpha_1);
        $for N in range(0, SIMD_TILE):
          v2r_${N} = xnn_fmadd_f16(vr_${N}, v2r_${N}, vone);

        // Compute 2^z * 2^r.
        $for N in range(0, SIMD_TILE):
          const xnn_simd_f16_t vy_${N} = xnn_mul_f16(v2z_${N}, v2r_${N});

        $for N in range(SIMD_TILE):
          xnn_storeu_f16(output + ${N} * xnn_simd_size_f16, vy_${N});
        output += ${BATCH_TILE};
      }
    for (; batch >= xnn_simd_bytes_f16; batch -= xnn_simd_bytes_f16) {
      xnn_simd_f16_t vx = xnn_loadu_f16(input);
      input += xnn_simd_size_f16;
      
      // Clamp `vz_prime = x * log2(e)` to the maximum exponents [-127, 128].
      xnn_simd_f16_t vz_prime = xnn_mul_f16(vx, vlog2e);
      vz_prime = xnn_min_f16(xnn_max_f16(vz_prime, vm15), v16);

      // Decompose x * log2e into `z` (integer part) and `r` (remainder).
      const xnn_simd_f16_t vz = xnn_qd_round_f16(vz_prime);
      const xnn_simd_f16_t vr = xnn_sub_f16(vz_prime, vz);
      
      // Compute 2^z.
      const xnn_simd_f16_t v2z = xnn_setexp_f16(vz);

      // Evaluate the interpolation polynomial for `2^r`.
      xnn_simd_f16_t v2r = xnn_fmadd_f16(vr, valpha_3, valpha_2);
      v2r = xnn_fmadd_f16(vr, v2r, valpha_1);
      v2r = xnn_fmadd_f16(vr, v2r, vone);

      // Compute 2^z * 2^r.
      const xnn_simd_f16_t vy = xnn_mul_f16(v2z, v2r);

      xnn_storeu_f16(output, vy);
      output += xnn_simd_size_f16;
    }
    $if SIMD_SIZE > 1:
      if XNN_UNLIKELY(batch != 0) {
        xnn_simd_f16_t vx = xnn_load_tail_f16(input, batch >> XNN_LOG2_SIZEOF_HALF);

        // Clamp `vz_prime = x * log2(e)` to the maximum exponents [-127, 128].
        xnn_simd_f16_t vz_prime = xnn_mul_f16(vx, vlog2e);
        vz_prime = xnn_min_f16(xnn_max_f16(vz_prime, vm15), v16);

        // Decompose x * log2e into `z` (integer part) and `r` (remainder).
        const xnn_simd_f16_t vz = xnn_qd_round_f16(vz_prime);
        const xnn_simd_f16_t vr = xnn_sub_f16(vz_prime, vz);
        
        // Compute 2^z.
        const xnn_simd_f16_t v2z = xnn_setexp_f16(vz);

        // Evaluate the interpolation polynomial for `2^r`.
        xnn_simd_f16_t v2r = xnn_fmadd_f16(vr, valpha_3, valpha_2);
        v2r = xnn_fmadd_f16(vr, v2r, valpha_1);
        v2r = xnn_fmadd_f16(vr, v2r, vone);

        // Compute 2^z * 2^r.
        const xnn_simd_f16_t vy = xnn_mul_f16(v2z, v2r);

        xnn_store_tail_f16(output, vy, batch >> XNN_LOG2_SIZEOF_HALF);
      }
  }

