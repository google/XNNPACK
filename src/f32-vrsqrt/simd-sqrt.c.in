// Copyright 2025 Google LLC
//
// This source code is licensed under the BSD-style license found in the
// LICENSE file in the root directory of this source tree.

$BATCH_TILES = tuple(int(bt) for bt in BATCH_TILES.split(","))
$SIMD_SIZE = BATCH_TILES[0]
$ABC = "0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZ"
#include <assert.h>
#include <stddef.h>
#include <stdint.h>

// Arch-specific SIMD wrapper.
#include "src/xnnpack/simd/f32-${ARCH}.h"

#include "src/xnnpack/common.h"
#include "src/xnnpack/microparams.h"
#include "src/xnnpack/vunary.h"

$for BATCH_TILE in BATCH_TILES:
  $assert BATCH_TILE % SIMD_SIZE == 0
  $assert BATCH_TILE >= SIMD_SIZE
  $SIMD_TILE = BATCH_TILE // SIMD_SIZE

  void xnn_f32_vrsqrt_ukernel__${ARCH}_sqrt_u${BATCH_TILE}(
      size_t batch, const float* input, float* output,
      const struct xnn_f32_default_params* unused_params) {
    assert(batch != 0);
    assert(batch % sizeof(float) == 0);
    assert(input != NULL);
    assert(output != NULL);

    XNN_SIMD_CONST_F32(vone, 1.0f);

    $if BATCH_TILE > SIMD_SIZE:
      for (; batch >= ${BATCH_TILE} * sizeof(float); batch -= ${BATCH_TILE} * sizeof(float)) {
        const xnn_simd_f32_t vx${ABC[0]} = xnn_loadu_f32(input);
        $for N in range(1, SIMD_TILE):
          const xnn_simd_f32_t vx${ABC[N]} = xnn_loadu_f32(input + ${N * SIMD_SIZE});
        input += ${BATCH_TILE};

        $for N in range(SIMD_TILE):
          xnn_simd_f32_t vy${ABC[N]} = xnn_sqrt_f32(vx${ABC[N]});
        $for N in range(SIMD_TILE):
          vy${ABC[N]} = xnn_div_f32(vone, vy${ABC[N]});

        // Store the results.
        xnn_storeu_f32(output, vy${ABC[0]});
        $for N in range(1, SIMD_TILE):
          xnn_storeu_f32(output + ${N * SIMD_SIZE}, vy${ABC[N]});
        output += ${BATCH_TILE};
      }

    for (; batch >= xnn_simd_bytes_f32; batch -= xnn_simd_bytes_f32) {
      const xnn_simd_f32_t vx = xnn_loadu_f32(input);
      input += xnn_simd_size_f32;

      xnn_simd_f32_t vy = xnn_sqrt_f32(vx);
      vy = xnn_div_f32(vone, vy);

      xnn_storeu_f32(output, vy);
      output += xnn_simd_size_f32;
    }

    if XNN_UNLIKELY(batch != 0) {
      assert(batch >= 1 * sizeof(float));
      assert(batch <= ${SIMD_SIZE - 1} * sizeof(float));
      const xnn_simd_f32_t vx = xnn_load_tail_f32(input, batch >> XNN_LOG2_SIZEOF_FLOAT);

      xnn_simd_f32_t vy = xnn_sqrt_f32(vx);
      vy = xnn_div_f32(vone, vy);

      xnn_store_tail_f32(output, vy, batch >> XNN_LOG2_SIZEOF_FLOAT);
    }
  }
