// Copyright 2024 Google LLC
//
// This source code is licensed under the BSD-style license found in the
// LICENSE file in the root directory of this source tree.

$assert DIV in ("DIV", "NR")
$BATCH_TILES = tuple(int(bt) for bt in BATCH_TILES.split(","))
$SIMD_SIZE = BATCH_TILES[0]
#include <assert.h>
#include <stddef.h>

#include "src/xnnpack/simd/f32-${ARCH}.h"

#include "src/xnnpack/common.h"
#include "src/xnnpack/microparams.h"
#include "src/xnnpack/vunary.h"

$for BATCH_TILE in BATCH_TILES:
  $assert BATCH_TILE % SIMD_SIZE == 0
  $assert BATCH_TILE >= SIMD_SIZE
  $SIMD_TILE = BATCH_TILE // SIMD_SIZE

  void xnn_f32_vapproxgelu_ukernel__${ARCH}_rational_12_10_${DIV.lower()}_u${BATCH_TILE}(
      size_t batch,
      const float* input,
      float* output,
      const struct xnn_f32_default_params unused_params[restrict XNN_MIN_ELEMENTS(1)])
  {
    assert(batch != 0);
    assert(batch % sizeof(float) == 0);
    assert(input != NULL);
    assert(output != NULL);
    assert(xnn_simd_size_f32 == ${SIMD_SIZE});

    // Cap the inputs to this value as `erf(x/sqrt(2))` will always be `+/-1.0f`
    // beyond this point. This value is chosen as the first floating point
    // number as of which the interpolation returns +/-1.0f.
    #if XNN_SIMD_HAS_NATIVE_FMA || (XNN_ARCH_RISCV && XNN_ENABLE_RISCV_VECTOR)
      $if DIV == "NR":
        XNN_SIMD_CONST_F32(vmax_x, 4.79519796e+00f);
        XNN_SIMD_CONST_F32(vmin_x, -4.84563780e+00f);
      $else:
        XNN_SIMD_CONST_F32(vmax_x, 4.84974098e+00f);
        XNN_SIMD_CONST_F32(vmin_x, -4.84974098e+00f);
    #else
      XNN_SIMD_CONST_F32(vmax_x, 4.86115026e+00f);
      XNN_SIMD_CONST_F32(vmin_x, -4.86115026e+00f);
    #endif  // XNN_SIMD_HAS_NATIVE_FMA

    // The monomial coefficients of the numerator polynomial (odd).
    XNN_SIMD_CONST_F32(valpha_1, 7.9788458347e-01f);
    XNN_SIMD_CONST_F32(valpha_3, 6.0803253204e-02f);
    XNN_SIMD_CONST_F32(valpha_5, 7.2898347862e-03f);
    XNN_SIMD_CONST_F32(valpha_7, 2.6887017884e-04f);
    XNN_SIMD_CONST_F32(valpha_9, 1.4302649106e-05f);
    XNN_SIMD_CONST_F32(valpha_11, 4.9544411240e-08f);


    // The monomial coefficients of the denominator polynomial (even).
    // XNN_SIMD_CONST_F32(vbeta_0, 1.0f);
    XNN_SIMD_CONST_F32(vbeta_2, 2.4369759858e-01f);
    XNN_SIMD_CONST_F32(vbeta_4, 2.4381054565e-02f);
    XNN_SIMD_CONST_F32(vbeta_6, 1.3060354395e-03f);
    XNN_SIMD_CONST_F32(vbeta_8, 7.6477612311e-05f);
    XNN_SIMD_CONST_F32(vbeta_10, 1.3433452750e-06f);

    XNN_SIMD_CONST_F32(vone, 1.0f);
    XNN_SIMD_CONST_F32(vhalf, 0.5f);
    $if DIV == "NR":
      // Constant needed for the Newton-Raphson iteration of the reciprocal.
      XNN_SIMD_CONST_F32(vtwo, 2.0f);

    $if SIMD_TILE > 1:
      for (; batch >= ${BATCH_TILE} * sizeof(float); batch -= ${BATCH_TILE} * sizeof(float)) {
        $for N in range(SIMD_TILE):
          const xnn_simd_f32_t vx_orig_${N} = xnn_loadu_f32(input + ${N} * xnn_simd_size_f32);
        input += ${BATCH_TILE};

        // Clamp the inputs to the interpolation range.
        $for N in range(SIMD_TILE):
          xnn_simd_f32_t vx_${N} = xnn_min_f32(vmax_x, vx_orig_${N});
        $for N in range(SIMD_TILE):
          vx_${N} = xnn_max_f32(vmin_x, vx_${N});

        // Since the polynomials are odd/even, we need x^2.
        $for N in range(SIMD_TILE):
          const xnn_simd_f32_t vx2_${N} = xnn_mul_f32(vx_${N}, vx_${N});

        // Evaluate the numerator polynomial p.
        $for N in range(SIMD_TILE):
          xnn_simd_f32_t vp_${N} = xnn_fmadd_f32(vx2_${N}, valpha_11, valpha_9);
        $for N in range(SIMD_TILE):
          vp_${N} = xnn_fmadd_f32(vx2_${N}, vp_${N}, valpha_7);
        $for N in range(SIMD_TILE):
          vp_${N} = xnn_fmadd_f32(vx2_${N}, vp_${N}, valpha_5);
        $for N in range(SIMD_TILE):
          vp_${N} = xnn_fmadd_f32(vx2_${N}, vp_${N}, valpha_3);
        $for N in range(SIMD_TILE):
          vp_${N} = xnn_fmadd_f32(vx2_${N}, vp_${N}, valpha_1);
        $for N in range(SIMD_TILE):
          vp_${N} = xnn_mul_f32(vx_${N}, vp_${N});

        // Evaluate the denominator polynomial q.
        $for N in range(SIMD_TILE):
          xnn_simd_f32_t vq_${N} = xnn_fmadd_f32(vx2_${N}, vbeta_10, vbeta_8);
        $for N in range(SIMD_TILE):
          vq_${N} = xnn_fmadd_f32(vx2_${N}, vq_${N}, vbeta_6);
        $for N in range(SIMD_TILE):
          vq_${N} = xnn_fmadd_f32(vx2_${N}, vq_${N}, vbeta_4);
        $for N in range(SIMD_TILE):
          vq_${N} = xnn_fmadd_f32(vx2_${N}, vq_${N}, vbeta_2);
        $for N in range(SIMD_TILE):
          vq_${N} = xnn_fmadd_f32(vx2_${N}, vq_${N}, vone);

        // Divide the numerator by the denominator.
        $if DIV == "DIV":
          $for N in range(SIMD_TILE):
            const xnn_simd_f32_t verf_${N} = xnn_div_f32(vp_${N}, vq_${N});
        $else:
          $for N in range(SIMD_TILE):
            xnn_simd_f32_t vrq_${N} = xnn_rcp_f32(vq_${N});
          for (size_t iter = 0; iter < XNN_SIMD_NUM_RCP_ITER_F32; iter++) {
            $for N in range(SIMD_TILE):
              vrq_${N} = xnn_mul_f32(vrq_${N}, xnn_fnmadd_f32(vrq_${N}, vq_${N}, vtwo));
          }
          // Note that we _could_ use a fused multiply-add to compute `p * rq + 1`,
          // but we actually want this to round to zero near the edges, so we
          // don't want the extended precision of the fused multiply-add.
          $for N in range(SIMD_TILE):
            const xnn_simd_f32_t verf_${N} = xnn_mul_f32(vp_${N}, vrq_${N});

        // Add one to the rational interpolant, and multiply by 0.5 times the
        // original input.
        $for N in range(SIMD_TILE):
          const xnn_simd_f32_t vy_${N} = xnn_mul_f32(xnn_mul_f32(vx_orig_${N}, vhalf),
                                              xnn_add_f32(verf_${N}, vone));

        $for N in range(SIMD_TILE):
          xnn_storeu_f32(output + ${N} * xnn_simd_size_f32, vy_${N});
        output += ${BATCH_TILE};
      }
    for (; batch >= xnn_simd_bytes_f32; batch -= xnn_simd_bytes_f32) {
      const xnn_simd_f32_t vx_orig = xnn_loadu_f32(input);
      input += xnn_simd_size_f32;

      // Clamp the inputs to the interpolation range.
      xnn_simd_f32_t vx = xnn_min_f32(vmax_x, vx_orig);
      vx = xnn_max_f32(vmin_x, vx);

      // Since the polynomials are odd/even, we need x^2.
      const xnn_simd_f32_t vx2 = xnn_mul_f32(vx, vx);

      // Evaluate the numerator polynomial p.
      xnn_simd_f32_t vp = xnn_fmadd_f32(vx2, valpha_11, valpha_9);
      vp = xnn_fmadd_f32(vx2, vp, valpha_7);
      vp = xnn_fmadd_f32(vx2, vp, valpha_5);
      vp = xnn_fmadd_f32(vx2, vp, valpha_3);
      vp = xnn_fmadd_f32(vx2, vp, valpha_1);
      vp = xnn_mul_f32(vx, vp);

      // Evaluate the denominator polynomial q.
      xnn_simd_f32_t vq = xnn_fmadd_f32(vx2, vbeta_10, vbeta_8);
      vq = xnn_fmadd_f32(vx2, vq, vbeta_6);
      vq = xnn_fmadd_f32(vx2, vq, vbeta_4);
      vq = xnn_fmadd_f32(vx2, vq, vbeta_2);
      vq = xnn_fmadd_f32(vx2, vq, vone);

      // Divide the numerator by the denominator and add one
      $if DIV == "DIV":
        const xnn_simd_f32_t verf =  xnn_div_f32(vp, vq);
      $else:
        xnn_simd_f32_t vrq = xnn_rcp_f32(vq);
        for (size_t iter = 0; iter < XNN_SIMD_NUM_RCP_ITER_F32; iter++) {
          vrq = xnn_mul_f32(vrq, xnn_fnmadd_f32(vrq, vq, vtwo));
        }
        // Note that we _could_ use a fused multiply-add to compute `p * rq + 1`,
        // but we actually want this to round to zero near the edges, so we
        // don't want the extended precision of the fused multiply-add.
        const xnn_simd_f32_t verf = xnn_mul_f32(vp, vrq);

      // Add one to the rational interpolant, and multiply by 0.5 times the
      // original input.
      const xnn_simd_f32_t vy = xnn_mul_f32(xnn_mul_f32(vx_orig, vhalf),
                                            xnn_add_f32(verf, vone));

      xnn_storeu_f32(output, vy);
      output += xnn_simd_size_f32;
    }
    $if SIMD_SIZE > 1:
      if XNN_UNLIKELY(batch != 0) {
        xnn_simd_f32_t vx_orig = xnn_load_tail_f32(input, batch >> XNN_LOG2_SIZEOF_FLOAT);

        // See above for comments.
        xnn_simd_f32_t vx = xnn_min_f32(vmax_x, vx_orig);
        vx = xnn_max_f32(vmin_x, vx);
        const xnn_simd_f32_t vx2 = xnn_mul_f32(vx, vx);
        xnn_simd_f32_t vp = xnn_fmadd_f32(vx2, valpha_11, valpha_9);
        vp = xnn_fmadd_f32(vx2, vp, valpha_7);
        vp = xnn_fmadd_f32(vx2, vp, valpha_5);
        vp = xnn_fmadd_f32(vx2, vp, valpha_3);
        vp = xnn_fmadd_f32(vx2, vp, valpha_1);
        vp = xnn_mul_f32(vx, vp);
        xnn_simd_f32_t vq = xnn_fmadd_f32(vx2, vbeta_10, vbeta_8);
        vq = xnn_fmadd_f32(vx2, vq, vbeta_6);
        vq = xnn_fmadd_f32(vx2, vq, vbeta_4);
        vq = xnn_fmadd_f32(vx2, vq, vbeta_2);
        vq = xnn_fmadd_f32(vx2, vq, vone);
        $if DIV == "DIV":
          const xnn_simd_f32_t verf =  xnn_div_f32(vp, vq);
        $else:
          xnn_simd_f32_t vrq = xnn_rcp_f32(vq);
          for (size_t iter = 0; iter < XNN_SIMD_NUM_RCP_ITER_F32; iter++) {
            vrq = xnn_mul_f32(vrq, xnn_fnmadd_f32(vrq, vq, vtwo));
          }
          const xnn_simd_f32_t verf = xnn_mul_f32(vp, vrq);
        const xnn_simd_f32_t vy = xnn_mul_f32(xnn_mul_f32(vx_orig, vhalf),
                                              xnn_add_f32(verf, vone));

        xnn_store_tail_f32(output, vy, batch >> XNN_LOG2_SIZEOF_FLOAT);
      }
  }
