// Copyright 2021 Google LLC
//
// This source code is licensed under the BSD-style license found in the
// LICENSE file in the root directory of this source tree.

#include <assert.h>
#include <riscv_vector.h>
#include <xnnpack/vbinary.h>

$assert DATATYPE in ["QS8", "QU8"]
$XINT8_T = {"QS8": "int8_t", "QU8": "uint8_t"}[DATATYPE]
$VSIZE = {"f2": "mf2", 1: "m1", 2: "m2"}[LMUL]
$VSIZE2 = {"f2": "m1", 1: "m2", 2: "m4"}[LMUL]
$VSIZE4 = {"f2": "m2", 1: "m4", 2: "m8"}[LMUL]

void xnn_${DATATYPE.lower()}_vmul_minmax_fp32_ukernel__rvv_u${BATCH_TILE}(
    size_t batch,
    const ${XINT8_T}* input_a,
    const ${XINT8_T}* input_b,
    ${XINT8_T}* output,
    const union xnn_${DATATYPE.lower()}_mul_minmax_params params[restrict XNN_MIN_ELEMENTS(1)])
{
  assert(batch != 0);
  assert(batch % sizeof(${XINT8_T}) == 0);
  assert(input_a != NULL);
  assert(input_b != NULL);
  assert(output != NULL);

  const int32_t a_zero_point = params->fp32_scalar.a_zero_point;
  const int32_t b_zero_point = params->fp32_scalar.b_zero_point;
  const float scale = params->fp32_scalar.scale;
  const float output_min_less_zero_point = params->fp32_scalar.output_min_less_zero_point;
  const float output_max_less_zero_point = params->fp32_scalar.output_max_less_zero_point;
  const float magic_bias = params->fp32_scalar.magic_bias;
  const int32_t magic_bias_less_output_zero_point = params->fp32_scalar.magic_bias_less_output_zero_point;

  do {
    int32_t vl = __riscv_vsetvl_e8${VSIZE}(batch);

    $if DATATYPE == "QS8":
      vint8${VSIZE}_t in_a_i8v = __riscv_vle8_v_i8${VSIZE}(input_a, vl);
      vint8${VSIZE}_t in_b_i8v = __riscv_vle8_v_i8${VSIZE}(input_b, vl);
      vint16${VSIZE2}_t a_i16v = __riscv_vwsub_vx_i16${VSIZE2}(in_a_i8v, a_zero_point, vl);
      vint16${VSIZE2}_t b_i16v = __riscv_vwsub_vx_i16${VSIZE2}(in_b_i8v, b_zero_point, vl);
    $else:
      vuint8${VSIZE}_t in_a_u8v = __riscv_vle8_v_u8${VSIZE}(input_a, vl);
      vuint8${VSIZE}_t in_b_u8v = __riscv_vle8_v_u8${VSIZE}(input_b, vl);
      vuint16${VSIZE2}_t a_u16v = __riscv_vwsubu_vx_u16${VSIZE2}(in_a_u8v, a_zero_point, vl);
      vuint16${VSIZE2}_t b_u16v = __riscv_vwsubu_vx_u16${VSIZE2}(in_b_u8v, b_zero_point, vl);
      vint16${VSIZE2}_t a_i16v = __riscv_vreinterpret_v_u16${VSIZE2}_i16${VSIZE2}(a_u16v);
      vint16${VSIZE2}_t b_i16v = __riscv_vreinterpret_v_u16${VSIZE2}_i16${VSIZE2}(b_u16v);

    vint32${VSIZE4}_t acc_i32v = __riscv_vwmul_vv_i32${VSIZE4}(a_i16v, b_i16v, vl);
    vfloat32${VSIZE4}_t acc_f32v = __riscv_vfcvt_f_x_v_f32${VSIZE4}(acc_i32v, vl);
    acc_f32v = __riscv_vfmul_vf_f32${VSIZE4}(acc_f32v, scale, vl);
    acc_f32v = __riscv_vfmin_vf_f32${VSIZE4}(__riscv_vfmax_vf_f32${VSIZE4}(acc_f32v, output_min_less_zero_point, vl), output_max_less_zero_point, vl);
    acc_f32v = __riscv_vfadd_vf_f32${VSIZE4}(acc_f32v, magic_bias, vl);

    $if DATATYPE == "QS8":
      vint32${VSIZE4}_t out_i32v = __riscv_vfcvt_x_f_v_i32${VSIZE4}(acc_f32v, vl);
      out_i32v = __riscv_vsub_vx_i32${VSIZE4}(out_i32v, magic_bias_less_output_zero_point, vl);
      vint16${VSIZE2}_t out_i16v = __riscv_vncvt_x_x_w_i16${VSIZE2}(out_i32v, vl);
      vint8${VSIZE}_t out_i8v = __riscv_vncvt_x_x_w_i8${VSIZE}(out_i16v, vl);
      __riscv_vse8_v_i8${VSIZE}(output, out_i8v, vl);
    $else:
      vuint32${VSIZE4}_t out_u32v = __riscv_vfcvt_xu_f_v_u32${VSIZE4}(acc_f32v, vl);
      out_u32v = __riscv_vsub_vx_u32${VSIZE4}(out_u32v, magic_bias_less_output_zero_point, vl);
      vuint16${VSIZE2}_t out_u16v = __riscv_vncvt_x_x_w_u16${VSIZE2}(out_u32v, vl);
      vuint8${VSIZE}_t out_u8v = __riscv_vncvt_x_x_w_u8${VSIZE}(out_u16v, vl);
      __riscv_vse8_v_u8${VSIZE}(output, out_u8v, vl);

    input_a += vl;
    input_b += vl;
    output += vl;
    batch -= vl;
  } while (batch != 0);
}
