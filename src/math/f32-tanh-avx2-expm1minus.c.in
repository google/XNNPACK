// Copyright 2023 Google LLC
//
// This source code is licensed under the BSD-style license found in the
// LICENSE file in the root directory of this source tree.

$import math
$assert RR == 1
$assert LOG2LUT in [0, 2, 3]
$assert P == H + 1 or P == H + 2
$assert P == H + 1 or not PS
$assert DIV in ["DIV", "NR1", "NR1ADJ"]
$assert SAT in ["MINMAX", "SELECT"]
$assert not PERM or LOG2LUT in [2, 3]
$LUT = 1 << LOG2LUT
#include <assert.h>
#include <stddef.h>
#include <stdint.h>
#include <math.h>

#include <immintrin.h>

#include <xnnpack/common.h>
#include <xnnpack/math.h>
#include <xnnpack/math-stubs.h>

$if LOG2LUT != 0 and not PERM:

  // Table of exp2(k / ${LUT}) values decremented (as integer) by (k << ${23-LOG2LUT}), k = 0..${LUT-1}
  extern XNN_INTERNAL const uint32_t xnn_table_exp2minus_k_over_${LUT}[${LUT}];

$if LOG2LUT == 0:
  $COEFFS = {6: ["0x1.FFFFFEp+0", "0x1.5554B0p+0", "0x1.555716p-1", "0x1.12278Ep-2", "0x1.6B7338p-4"]}[P]
$elif LOG2LUT == 2:
  $COEFFS = {4: ["0x1.000002p+1", "0x1.557082p+0", "0x1.554F9Ap-1"]}[P]
$elif LOG2LUT == 3:
  $COEFFS = {4: ["0x1.000000p+1", "0x1.555C20p+0", "0x1.5558ECp-1"]}[P]
$POLYNOMIAL = "c%d" % P
$for i in reversed(range(2, P)):
$  POLYNOMIAL = "(c%d + t * %s)" % (i, POLYNOMIAL)
$if P == H + 1:
  $POLYNOMIAL = "(2 + t * %s)" % POLYNOMIAL
$else:
  $COEFFS = [float.hex(0.5 * float.fromhex(c)).upper().replace("0X", "0x").replace("0000000P", "p") for c in COEFFS]
$LUT_SUFFIX = "" if LOG2LUT == 0 else "lut%d_" % LUT
$POLY_SUFFIX = "p%dh%d%s_" % (P, H, "ps" if PS else "ts")
$GATHER_SUFFIX = "perm_" if PERM else "gather_" if LOG2LUT != 0 else ""
$DIV_SUFFIX = DIV.lower()
void xnn_math_f32_tanh__avx2_expm1minus_rr${RR}_${LUT_SUFFIX}${POLY_SUFFIX}${GATHER_SUFFIX}${DIV_SUFFIX}(
    size_t n,
    const float* input,
    float* output)
{
  assert(n % sizeof(__m256) == 0);

  // Mask for the sign bit.
  const __m256 vsign_mask = _mm256_set1_ps(-0.0f);
  // The largest z for which tanhf(z) is saturated at -1.0f.
  const __m256 vsat_cutoff = _mm256_set1_ps(-0x1.205968p+3f);
  const __m256 vlog2e = _mm256_set1_ps(0x1.715476p+0f);
  $if LOG2LUT == 0:
    // Large number such that ulp(magic bias) == 0.5 and magic bias === 63.5 mod 2**21.
    const __m256 vmagic_bias = _mm256_set1_ps(0x1.8000FEp+22f);
  $else:
    // Large number such that ulp(magic bias) == exp2(${-1-LOG2LUT})
    const __m256 vmagic_bias = _mm256_set1_ps(0x1.800000p+${22-LOG2LUT}f);
  $if LOG2LUT != 0:
    $if PERM:
      $if LOG2LUT == 2:
        // Table of exp2(k / 4) values decremented (as integer) by (k << 21), k = 0..3
        const __m256 vtable = _mm256_set_ps(
          0x1.EE89FAp-1f, 0x1.EA09E6p-1f, 0x1.F06FE0p-1f, 0x1.000000p+0f,
          0x1.EE89FAp-1f, 0x1.EA09E6p-1f, 0x1.F06FE0p-1f, 0x1.000000p+0f);
      $elif LOG2LUT == 3:
        // Table of exp2(k / 8) values decremented (as integer) by (k << 20), k = 0..7
        const __m256i vtable = _mm256_set_epi32(
          0x3F7AC0C7, 0x3F7744FD, 0x3F75672A, 0x3F7504F3, 0x3F75FED7, 0x3F7837F0, 0x3F7B95C2, 0x3F800000);
    $else:
      // Mask for the lowest ${LOG2LUT} bits
      const __m256i vindex_mask = _mm256_set1_epi32(0x${"%X" % (LUT-1)});
  const __m256 vminus_ln2 = _mm256_set1_ps(-0x1.62E430p-1f);
  // Coefficients of polynomial approximation
  $if P == H + 1:
    //   exp(2t) - 1 ~ t * ${POLYNOMIAL}
  $else:
    //   exp(2t) - 1 ~ 2 * (t + t * (t * ${POLYNOMIAL}))
  // on [-log(2)/${4*LUT}, log(2)/${4*LUT}]
  $for i in reversed(range(len(COEFFS))):
    const __m256 vc${i+P-len(COEFFS)+1} = _mm256_set1_ps(${COEFFS[i]}f);
  $if P != H + 1:
    const __m256 vminus_one = _mm256_set1_ps(-1.0f);
  const __m256 vtwo = _mm256_set1_ps(2.0f);
  $if P == H + 1:
    const __m256 vminus_one = _mm256_set1_ps(-1.0f);

  for (; n != 0; n -= sizeof(__m256)) {
    const __m256 vx = _mm256_load_ps(input);
    input += 8;

    // General structure of the algorithm:
    //
    //           / expm1(2x) / (2 + expm1(2x)) if x <= 0
    //   f(x) :=
    //           \ -f(-x) if x >= 0
    //
    // First we compute f(z) := expm1(2z) / (2 + expm1(2z)) where z = -abs(x), then negate the result if x >= 0.
    __m256 vz = _mm256_or_ps(vx, vsign_mask);

    // Inverted mask for the sign of input: 0x00000000 for negative x, 0x80000000 for positive x.
    const __m256 vinvsignx = _mm256_xor_ps(vx, vz);

    $if SAT == "MINMAX":
      // The function saturates at -1 for large negative inputs: tanhf(z) == -1.0f for z <= sat_cutoff ~= -9.010913.
      // To guarantee this behaviour, we clip input z at sat_cutoff, and leverage the fact that for our implementation
      // tanhf(sat_cutoff) == -1.0f. NaN inputs are passed unchanged.
      vz = _mm256_max_ps(vsat_cutoff, vz);
    $elif SAT == "SELECT":
      // The function saturates at -1 for large negative inputs: tanhf(z) == -1.0f for z <= sat_cutoff ~= -9.010913.
      // To guarantee this behaviour, we compute the saturation mask here, and later use it to replace computed outputs
      // with the saturation value (-1). Note that for NaN inputs the saturation mask is inactive.
      const __m256 vm = _mm256_cmp_ps(vz, vsat_cutoff, _CMP_LE_OS);

    // Compute reduced argument n := round(z / log(2), ${1+LOG2LUT}).
    // We do it by adding a large number (magic bias), which cause rounding of the result to ${1+LOG2LUT} fractional ${"bit" if LOG2LUT == 0 else "bits"},
    // then subtracing the large number back. The trick with adding large number is valid only within certain bounds
    // (|z / log(2)| <= 2**${21-LOG2LUT}, i.e. |z| <= 0x1.62E43p+${20-LOG2LUT} = ${math.ldexp(float.fromhex("0x1.62E43p+20"), -LOG2LUT)}), but that is acceptable, because inputs x
    // outside of [-9.010913, 9.010913] (i.e. z outsize [-9.010913, 0]) saturate tanhf(x).
    $if LOG2LUT == 0:
      // Additionally, we fuse addition of the floating-point exponent bias (127) into the magic bias.
    // Note that addition-subtraction of the large number doesn't cause overflow for inputs in this range.
    __m256 vn = _mm256_fmadd_ps(vz, vlog2e, vmagic_bias);

    $if LOG2LUT == 0:
      // Create a floating-point number s (scale) such that s == 2**(2n) for inputs which don't cause underflow, i.e.
      // -9.010913 <= z <= 0, and -13 <= n <= 0 accordingly.
      const __m256 vs = _mm256_castsi256_ps(_mm256_slli_epi32(_mm256_castps_si256(vn), 23));
    $else:
      // Create a floating-point number s (scale) such that s := 2**(2n) for valid inputs, i.e. -9.010913 <= z <= 0. As
      // n has ${1+LOG2LUT} fractional bits, we split s == 2**(2n) = 2**int(2n) * 2**frac(2n). We create s in two steps:
      // 1. Fetch 2**frac(2n) from the table using the ${LOG2LUT} low bits of n, as integer. Note that the fetched values are in
      //    the [1.0, 2.0) range, i.e. their unbiased floating-point exponent is 0.
      // 2. Adjust fetched value by addition of int(2n) to its floating-point exponent. The result is always a normalized
      //    number, because for -9.010913 <= z <= 0 we have -13 <= int(n) <= 0, and thus the adjusted exponent is not
      //    lower than -13.
      //
      // Shift bits ${LOG2LUT}:${LOG2LUT+8} into 23:31 (position of floating-point exponent).
      const __m256i ve = _mm256_slli_epi32(_mm256_castps_si256(vn), ${23-LOG2LUT});

      // Use bits 0:${LOG2LUT} bits of n, as integer, as an index for table lookup of l := 2**frac(2n).
      $if PERM:
        $if LOG2LUT == 2:
          const __m256i vl = _mm256_castps_si256(_mm256_permutevar_ps(vtable, _mm256_castps_si256(vn)));
        $elif LOG2LUT == 3:
          const __m256i vl = _mm256_permutevar8x32_epi32(vtable, _mm256_castps_si256(vn));
      $else:
        const __m256i vidx = _mm256_and_si256(_mm256_castps_si256(vn), vindex_mask);
        const __m256i vl = _mm256_i32gather_epi32((const int*) xnn_table_exp2minus_k_over_${LUT}, vidx, sizeof(uint32_t));

      // Adjust exponent of the value l fetched from the table to get the final s value.
      const __m256 vs = _mm256_castsi256_ps(_mm256_add_epi32(vl, ve));

    // Subtract the large number back to get final n := round(z / log(2), ${1+LOG2LUT}) as a floating-point number.
    vn = _mm256_sub_ps(vn, vmagic_bias);

    // Compute reduced argument t := z - n * log(2).
    const __m256 vt = _mm256_fmadd_ps(vn, vminus_ln2, vz);

    // Compute degree-${P} polynomial approximation for exp(2t) - 1 on [-log(2)/${4*LUT}, log(2)/${4*LUT}].
    $if P == H + 1:
      //   P(t) = t * ${POLYNOMIAL}
      //        = t * p
    $else:
      //   P(t) = 2 * (t + t * (t * ${POLYNOMIAL}))
      //        = 2 * (t + t * p)
    __m256 vp = vc${P};
    $for i in reversed(range(2, P)):
      vp = _mm256_fmadd_ps(vp, vt, vc${i});
    $if P == H + 1:
      vp = _mm256_fmadd_ps(vp, vt, vtwo);
    $else:
      vp = _mm256_mul_ps(vp, vt);

    // Reconstruct the exp(2z) - 1 value:
    $if P == H + 1:
      //   exp(2z) - 1 = s * (t * ${POLYNOMIAL} + 1) - 1
      //               = s * t * p + (s - 1)
      $if PS:
        //               = (s - 1) + (p * s) * t
      $else:
        //               = (s - 1) + (t * s) * p
    $else:
      //   exp(2z) - 1 = s * (2 * (t + t * (t * ${POLYNOMIAL})) + 1) - 1
      //               = s * (2 * (t + t * p) + 1) - 1
      //               = (s - 1) + 2 * ((t * s) + (t * s) * p)
    $if PS:
      const __m256 vps = _mm256_mul_ps(vp, vs);
    $else:
      const __m256 vts = _mm256_mul_ps(vt, vs);
    const __m256 vsmo = _mm256_add_ps(vs, vminus_one);
    $if P == H + 1:
      $if PS:
        const __m256 vemo = _mm256_fmadd_ps(vt, vps, vsmo);
      $else:
        const __m256 vemo = _mm256_fmadd_ps(vp, vts, vsmo);
    $else:
      vp = _mm256_fmadd_ps(vp, vts, vts);
      const __m256 vemo = _mm256_fmadd_ps(vp, vtwo, vsmo);

    // Denominator of the tanh fraction: exp(2z) + 1 = expm1(2z) + 2
    const __m256 vepo = _mm256_add_ps(vemo, vtwo);

    $if DIV == "DIV":
      // Reconstruct tanh(z) = expm1(2z) / (expm1(2z) + 2)
      __m256 vy = _mm256_div_ps(vemo, vepo);
    $else:
      // Use Newton-Raphson method (${"1 iteration" if DIV.startswith("NR1") else "2 iterations"}) to compute reciprocal of the denominator.
      // Note: 2 < exp(2z) + 1 <= 3, because z <= 0 and 0 < exp(2z) <= 1.
      // Thus the reciprocal of the denominator never overflows.
      __m256 vrepo = _mm256_rcp_ps(vepo);
      const __m256 verepo = _mm256_fnmsub_ps(vrepo, vepo, vminus_one);
      vrepo = _mm256_fmadd_ps(verepo, vrepo, vrepo);

      // Reconstruct tanh(z) := expm1(2z) / (2 + expm1(2z))
      __m256 vy = _mm256_mul_ps(vemo, vrepo);

      $if DIV.endswith("ADJ"):
        // Adjust reconstructred expm1(2z) / (2 + expm1(2z)) to match the correctly rounded division result
        const __m256 vey = _mm256_fnmadd_ps(vy, vepo, vemo);
        vy = _mm256_fmadd_ps(vey, vrepo, vy);

    $if SAT == "SELECT":
      // Saturate tanh(z) at -1 for large inputs.
      vy = _mm256_blendv_ps(vy, vminus_one, vm);

    // Reconstruct tanh(x):
    //
    //             / tanh(z) if x <= 0
    //   tanh(x) =
    //             \ -tanh(z) if x >= 0
    vy = _mm256_xor_ps(vy, vinvsignx);

    _mm256_store_ps(output, vy);
    output += 8;
  }
}
