// Copyright 2023 Google LLC
//
// This source code is licensed under the BSD-style license found in the
// LICENSE file in the root directory of this source tree.

$import math
$assert RR == 1 or RR == 2
$assert LOG2LUT in [0, 2, 3, 4, 5, 6]
$assert P == H + 1 or P == H + 2
$assert P == H + 1 or not PS
$assert DIV in ["DIV", "NR2RECPS", "NR2RECPSADJ", "NR1RECPS1FMA", "NR1RECPS1FMAADJ", "NR2FMA", "NR2FMAADJ"]
$LUT = 1 << LOG2LUT
#include <assert.h>
#include <stddef.h>
#include <stdint.h>
#include <math.h>

#include <arm_neon.h>

#include <xnnpack/common.h>
#include <xnnpack/math.h>
#include <xnnpack/math-stubs.h>

$if LOG2LUT != 0:

  // Table of exp2(k / ${LUT}) values decremented (as integer) by (k << ${23-LOG2LUT}), k = 0..${LUT-1}
  extern XNN_INTERNAL const uint32_t xnn_table_exp2minus_k_over_${LUT}[${LUT}];

$if LOG2LUT == 0:
  $COEFFS = {6: ["0x1.FFFFFEp+0", "-0x1.5554B0p+0", "0x1.555716p-1", "-0x1.12278Ep-2", "0x1.6B7338p-4"]}[P]
  $LN2 = ("0x1.62E420p-1", "0x1.FDF474p-22")
$elif LOG2LUT == 3:
  $COEFFS = {4: ["0x1.000000p+1", "-0x1.555C20p+0", "0x1.5558ECp-1"]}[P]
  $LN2 = ("0x1.62E400p-1", "0x1.7F7D1Cp-20")
$POLYNOMIAL = "c%d" % P
$for i in reversed(range(2, P)):
$  POLYNOMIAL = "(c%d + t * %s)" % (i, POLYNOMIAL)
$if P == H + 1:
  $POLYNOMIAL = "(-2 + t * %s)" % POLYNOMIAL
$else:
  $COEFFS = [float.hex(-0.5 * float.fromhex(c)).upper().replace("0X", "0x").replace("0000000P", "p") for c in COEFFS]
$VMLAQ_F32 = "vfmaq_f32" if FMA else "vmlaq_f32"
$VMLSQ_F32 = "vfmsq_f32" if FMA else "vmlsq_f32"
$LUT_SUFFIX = "" if LOG2LUT == 0 else "lut%d_" % LUT
$POLY_SUFFIX = "p%dh%d%s_" % (P, H, "ps" if PS else "ts")
$DIV_SUFFIX = DIV.lower()
$ISA = "aarch64_neonfma" if DIV == "DIV" else "neonfma" if FMA else "neon"
void xnn_math_f32_tanh__${ISA}_expm1minus_rr${RR}_${LUT_SUFFIX}${POLY_SUFFIX}${DIV_SUFFIX}(
    size_t n,
    const float* input,
    float* output)
{
  assert(n % sizeof(float32x4_t) == 0);

  // The smallest z for which tanhf(-z) is saturated at -1.0f.
  const float32x4_t vsat_cutoff = vmovq_n_f32(0x1.205968p+3f);
  const float32x4_t vminus_log2e = vmovq_n_f32(-0x1.715476p+0f);
  $if LOG2LUT == 0:
    // Large number such that ulp(magic bias) == 0.5 and magic bias === 63.5 mod 2**21.
    const float32x4_t vmagic_bias = vmovq_n_f32(0x1.8000FEp+22f);
  $else:
    // Large number such that ulp(magic bias) == exp2(${-1-LOG2LUT})
    const float32x4_t vmagic_bias = vmovq_n_f32(0x1.800000p+${22-LOG2LUT}f);
  $if LOG2LUT != 0:
    // Mask for the lowest ${LOG2LUT} bits
    const uint64x2_t vindex_mask = vreinterpretq_u64_u32(vmovq_n_u32(UINT32_C(0x${"%X" % (LUT-1)})));
  $if RR == 1:
    const float32x4_t vln2 = vmovq_n_f32(0x1.62E430p-1f);
  $else:
    $if not FMA:
      // Last ${4+LOG2LUT} bits are zeroes
    const float32x4_t vln2_hi = vmovq_n_f32(${LN2[0]}f);
    const float32x4_t vln2_lo = vmovq_n_f32(${LN2[1]}f);
  // Coefficients of polynomial approximation
  $if P == H + 1:
    //   exp(-2t) - 1 ~ t * ${POLYNOMIAL}
  $else:
    //   exp(-2t) - 1 ~ -2 * (t + t * (t * ${POLYNOMIAL}))
  // on [-log(2)/${4*LUT}, log(2)/${4*LUT}]
  $for i in reversed(range(len(COEFFS))):
    const float32x4_t vc${i+P-len(COEFFS)+1} = vmovq_n_f32(${COEFFS[i]}f);
  $if P == H + 1:
    const float32x4_t vtwo = vmovq_n_f32(2.0f);
  const float32x4_t vone = vmovq_n_f32(1.0f);
  $if P != H + 1:
    const float32x4_t vtwo = vmovq_n_f32(2.0f);
  // Mask for the sign bit.
  const uint32x4_t vsign_mask = vmovq_n_u32(UINT32_C(0x80000000));

  for (; n != 0; n -= sizeof(float32x4_t)) {
    const float32x4_t vx = vld1q_f32(input); input += 4;

    // General structure of the algorithm:
    //
    //           / -expm1(-2x) / (2 + expm1(-2x)) if x >= 0
    //   f(x) :=
    //           \ -f(-x) if x <= 0
    //
    // First we compute y := expm1(-2z) / (2 + expm1(-2z)) where z = abs(x),
    // then set its sign according to the sign of x: f(x) := sign(x) * abs(y).
    float32x4_t vz = vabsq_f32(vx);

    // The function saturates at -1 for large positive inputs: tanhf(-z) == -1.0f for z >= sat_cutoff ~= 9.010913.
    // To guarantee this behaviour, we clip input z at sat_cutoff, and leverage the fact that for our implementation
    // tanhf(sat_cutoff) == -1.0f. NaN inputs are passed unchanged.
    vz = vminq_f32(vz, vsat_cutoff);

    // Compute reduced argument n := round(-z / log(2), ${1+LOG2LUT}).
    // We do it by adding a large number (magic bias), which cause rounding of the result to ${1+LOG2LUT} fractional ${"bit" if LOG2LUT == 0 else "bits"},
    // then subtracing the large number back. The trick with adding large number is valid only within certain bounds
    // (|-z / log(2)| <= 2**${21-LOG2LUT}, i.e. |z| <= 0x1.62E43p+${20-LOG2LUT} = ${math.ldexp(float.fromhex("0x1.62E43p+20"), -LOG2LUT)}), but that is acceptable, because inputs x
    // outside of [-9.010913, 9.010913] (i.e. z outsize [0, 9.010913]) saturate tanhf(x).
    $if LOG2LUT == 0:
      // Additionally, we fuse addition of the floating-point exponent bias (127) into the magic bias.
    // Note that addition-subtraction of the large number doesn't cause overflow for inputs in this range.
    float32x4_t vn = ${VMLAQ_F32}(vmagic_bias, vz, vminus_log2e);

    $if LOG2LUT == 0:
      // Create a floating-point number s (scale) such that s == 2**(2n) for inputs which don't cause underflow, i.e.
      // 0 <= z <= 9.010913, and -13 <= n <= 0 accordingly.
      const float32x4_t vs = vreinterpretq_f32_s32(vshlq_n_s32(vreinterpretq_s32_f32(vn), 23));
    $else:
      // Create a floating-point number s (scale) such that s := 2**(2n) for valid inputs, i.e. 0 <= z <= 9.010913. As
      // n has ${1+LOG2LUT} fractional bits, we split s == 2**(2n) = 2**int(2n) * 2**frac(2n). We create s in two steps:
      // 1. Fetch 2**frac(2n) from the table using the ${LOG2LUT} low bits of n, as integer. Note that the fetched values are in
      //    the [1.0, 2.0) range, i.e. their unbiased floating-point exponent is 0.
      // 2. Adjust fetched value by addition of int(2n) to its floating-point exponent. The result is always a normalized
      //    number, because for 0 <= z <= 9.010913 we have -13 <= int(n) <= 0, and thus the adjusted exponent is not
      //    lower than -13.
      //
      // Shift bits ${LOG2LUT}:${LOG2LUT+8} into 23:31 (position of floating-point exponent).
      const uint32x4_t ve = vshlq_n_u32(vreinterpretq_u32_f32(vn), ${23-LOG2LUT});

      // Use bits 0:${LOG2LUT} bits of n, as integer, as an index for table lookup of l := 2**frac(n).
      const uint64x2_t vidx = vandq_u64(vreinterpretq_u64_f32(vn), vindex_mask);
      const uint64_t vidx_lo = vgetq_lane_u64(vidx, 0);
      const uint64_t vidx_hi = vgetq_lane_u64(vidx, 1);
      uint32x2_t vl_lo = vld1_dup_u32(&xnn_table_exp2minus_k_over_${LUT}[(uint32_t) vidx_lo]);
      uint32x2_t vl_hi = vld1_dup_u32(&xnn_table_exp2minus_k_over_${LUT}[(uint32_t) vidx_hi]);
      vl_lo = vld1_lane_u32(&xnn_table_exp2minus_k_over_${LUT}[(uint32_t) (vidx_lo >> 32)], vl_lo, 1);
      vl_hi = vld1_lane_u32(&xnn_table_exp2minus_k_over_${LUT}[(uint32_t) (vidx_hi >> 32)], vl_hi, 1);
      const uint32x4_t vl = vcombine_u32(vl_lo, vl_hi);

      // Adjust exponent of the value l fetched from the table to get the final s value.
      const float32x4_t vs = vreinterpretq_f32_u32(vaddq_u32(vl, ve));

    // Subtract the large number back to get final n := round(-z / log(2), ${1+LOG2LUT}) as a floating-point number.
    vn = vsubq_f32(vn, vmagic_bias);

    // Compute reduced argument t := z + n * log(2). Note that -t = -z - n * log(2).
    $if RR == 1:
      const float32x4_t vt = ${VMLAQ_F32}(vz, vn, vln2);
    $else:
      // Use Cody-Waite range reduction method (note two constants to represent log(2)) to improve accuracy.
      float32x4_t vt = ${VMLAQ_F32}(vz, vn, vln2_hi);
      vt = ${VMLAQ_F32}(vt, vn, vln2_lo);

    // Compute degree-${P} polynomial approximation for exp(-2t) - 1 on [-log(2)/${4*LUT}, log(2)/${4*LUT}].
    $if P == H + 1:
      //   P(t) = t * ${POLYNOMIAL}
      //        = t * (-p)
    $else:
      //   P(t) = -2 * (t + t * (t * ${POLYNOMIAL}))
      //        = -2 * (t + t * p)
    float32x4_t vp = ${VMLAQ_F32}(vc${P-1}, vc${P}, vt);
    $for i in reversed(range(2, P-1)):
      vp = ${VMLAQ_F32}(vc${i}, vp, vt);
    $if P == H + 1:
      vp = ${VMLSQ_F32}(vtwo, vp, vt);
    $else:
      vp = vmulq_f32(vp, vt);

    // Reconstruct the exp(-2z) - 1 value:
    $if P == H + 1:
      //   exp(-2z) - 1 = s * (t * ${POLYNOMIAL} + 1) - 1
      //                = s * t * (-p) + (s - 1)
      $if PS:
        //                = (s - 1) - (p * s) * t
      $else:
        //                = (s - 1) - (t * s) * p
    $else:
      //   exp(-2z) - 1 = s * (-2 * (t + t * (t * ${POLYNOMIAL})) + 1) - 1
      //                = s * (-2 * (t + t * p) + 1) - 1
      //                = (s - 1) - 2 * ((t * s) + (t * s) * p)
    $if PS:
      const float32x4_t vps = vmulq_f32(vp, vs);
    $else:
      const float32x4_t vts = vmulq_f32(vt, vs);
    const float32x4_t vsmo = vsubq_f32(vs, vone);
    $if P == H + 1:
      $if PS:
        const float32x4_t vemo = ${VMLSQ_F32}(vsmo, vt, vps);
      $else:
        const float32x4_t vemo = ${VMLSQ_F32}(vsmo, vp, vts);
    $else:
      vp = ${VMLAQ_F32}(vts, vp, vts);
      const float32x4_t vemo = ${VMLSQ_F32}(vsmo, vp, vtwo);

    // Denominator of the tanh fraction: exp(-2z) + 1 = expm1(-2z) + 2
    const float32x4_t vepo = vaddq_f32(vemo, vtwo);

    $if DIV == "DIV":
      // Reconstruct y = expm1(-2z) / (expm1(-2z) + 2)
      float32x4_t vy = vdivq_f32(vemo, vepo);
    $else:
      // Use Newton-Raphson method (2 iterations) to compute reciprocal of the denominator.
      // Note: 2 < exp(-2z) + 1 <= 3, because z <= 0 and 0 < exp(-2z) <= 1.
      // Thus the reciprocal of the denominator never overflows.
      float32x4_t vrepo = vrecpeq_f32(vepo);
      $if DIV.startswith("NR1RECPS") or DIV.startswith("NR2RECPS"):
        float32x4_t verepo = vrecpsq_f32(vrepo, vepo);
        vrepo = vmulq_f32(vrepo, verepo);
      $else:
        float32x4_t verepo = vfmsq_f32(vone, vrepo, vepo);
        vrepo = vfmaq_f32(vrepo, vrepo, verepo);
      $if DIV.startswith("NR2RECPS"):
        verepo = vrecpsq_f32(vrepo, vepo);
        vrepo = vmulq_f32(vrepo, verepo);
      $else:
        verepo = vfmsq_f32(vone, vrepo, vepo);
        vrepo = vfmaq_f32(vrepo, vrepo, verepo);

      // Reconstruct y = expm1(-2z) / (expm1(-2z) + 2)
      float32x4_t vy = vmulq_f32(vemo, vrepo);

      $if DIV.endswith("ADJ"):
        // Adjust reconstructred expm1(-2z) / (2 + expm1(-2z)) to match the correctly rounded division result
        const float32x4_t vey = vfmsq_f32(vemo, vy, vepo);
        vy = vfmaq_f32(vy, vey, vrepo);

    // Reconstruct tanh(x) = copysign(y, x)
    vy = vbslq_f32(vsign_mask, vx, vy);

    vst1q_f32(output, vy); output += 4;
  }
}
