// Copyright 2024 Google LLC
//
// This source code is licensed under the BSD-style license found in the
// LICENSE file in the root directory of this source tree.

$assert NR == 64
$assert KR == 4
$assert DATATYPE in ["QS8", "X8"]
$assert TYPE in ["int8_t"]
$assert IZP in [0, 128]
$UNROLL = 0

#include <assert.h>
#include <stddef.h>
#include <stdint.h>

#include <immintrin.h>

#include "src/xnnpack/packw.h"
#include "src/xnnpack/unaligned.h"
$if PREFETCH:
  #include "src/xnnpack/prefetch.h"

XNN_INLINE static uint32_t safe_load_u32(const void* src, size_t k) {
  uint32_t value = 0;
  const uint8_t* bytes = (const uint8_t*)src;
  for (size_t i = 0; i < k; ++i) {
    value |= (uint32_t) bytes[i] << (i * 8);
  }
  return value;
}

$BTYPE = {"QS8": "int32_t", "QS4": "int32_t", "X8": "uint32_t"}[DATATYPE]
$WTYPE = {"QS8": "int8_t", "QS4": "uint8_t", "X8": "int8_t"}[DATATYPE]
$PACKEDWTYPE = {"QS8": "int8_t", "QS4": "void", "X8": "int8_t"}[DATATYPE]
$SCALETYPE = {"QS8": "void", "QS4": "float", "X8": "void"}[DATATYPE]
$PARAMTYPE = {"QS8": "void", "QS4": "struct xnn_qs8_qc4w_packing_params", "X8": "void"}[DATATYPE]
$if DATATYPE in ["QS8", "QS4"]:
  $_MM256_DPBUSD_EPI32 = "mm256_dpbusd_epi32_madd" if VARIANT == "MADD" else "_mm256_dpbusd_avx_epi32" if AVX == 2 else "_mm256_dpbusd_epi32"
  $ISA = "avx2" if VARIANT == "MADD" else "avxvnni" if AVX == 2 else "avx256vnni"
$else:
  $ISA = "avx2" if AVX == 2 else "avx256skx"
$DATATYPE_SPEC = "qs8_to_qu8" if IZP == 128 else {"QS8": "qs8", "QS4": "qs8_qc4w", "X8": "x8"}[DATATYPE]
$if DATATYPE in ["QS4"]:
  // Convert a vector from packed nibbles to planar, and accumulate sum
  static XNN_INTRINSIC
  __m256i xnn_packed2planar(__m256i* vacc, const __m256i v, const __m256i vmask, const __m256i vone) {
     const __m256i v0213 = _mm256_shuffle_epi32(v, _MM_SHUFFLE(3, 1, 2, 0));
     const __m256i vt = _mm256_slli_epi32(v0213, 4);     // isolate lower int4
     const __m256i vh = _mm256_and_si256(v0213, vmask);  // isolate upper int4
     const __m256i vl = _mm256_and_si256(vt, vmask);
     const __m256i v01 = _mm256_unpacklo_epi8(vl, vh);
     const __m256i v23 = _mm256_unpackhi_epi8(vl, vh);
     *vacc = ${_MM256_DPBUSD_EPI32}(*vacc, vone, v01);
     *vacc = ${_MM256_DPBUSD_EPI32}(*vacc, vone, v23);
     const __m256i vl01 = _mm256_srli_epi32(v01, 4);
     return _mm256_or_si256(vl01, v23);
  }

void xnn_${DATATYPE_SPEC}_packw_gemm_goi_ukernel_x${NR}c${KR}__${ISA}${"_prfm" if PREFETCH else ""}(
  size_t g,
  size_t nc,
  size_t kc,
  size_t nr,
  size_t kr,
  size_t sr,
  const ${WTYPE}* weights,
  const ${BTYPE}* bias,
  const ${SCALETYPE}* scale,
  ${PACKEDWTYPE}* packed_weights,
  size_t extra_bytes,
  const ${PARAMTYPE}* params)
{
  assert(g != 0);
  assert(nc != 0);
  assert(kc != 0);
  assert(nr == ${NR});
  assert(kr == ${KR});
  assert(sr == 1);
  assert(weights != NULL);
  assert(packed_weights != NULL);
  assert(params != NULL);
  $if DATATYPE == "QS4":
    assert(kc % 2 == 0);  // This kernel does not support odd KC
    kc >>= 1;  // KR=8 4 bit with 2 planes is 8 bytes.  Measure in bytes

  ${TYPE}* out = (${TYPE}*) packed_weights;
  const ${BTYPE}* b = (const ${BTYPE}*) bias;

  $if DATATYPE in ["QS8"]:
    const __m256i vone = _mm256_set1_epi8(1);
    const __m256i vzeropoint = _mm256_set1_epi32((int32_t) (params ? (((const struct xnn_qs8_packw_params*) params)->input_zero_point + ${IZP}): ${IZP}));
  $elif DATATYPE in ["QS4"]:
    const __m256i vone = _mm256_set1_epi8(1);
    const __m256i vmask = _mm256_set1_epi8(0xF0);
    const __m256i vzeropoint = _mm256_set1_epi32((int32_t) params->input_zero_point + ${IZP});
    const __m256i vkernel_zero_point = _mm256_set1_epi32((uint32_t) params->kernel_zero_point * 0x11111111);
    assert(params->kernel_zero_point == 8 || params->kernel_zero_point == 0);

  do {
    // NC main loop multiple of ${NR}
    const ${TYPE}* w0 = (const ${TYPE}*) weights;
    size_t n = nc;
    for (;n >= ${NR}; n -= ${NR}) {
      $for N in range(1, NR):
        const ${TYPE}* w${N} = w${N-1} + kc;

      $if DATATYPE in ["QS8", "QS4"]:
        ${BTYPE}* packed_b = (${BTYPE}*) out;
      if XNN_LIKELY(b != NULL) {
        $for N in range(0, NR, 8):
          const __m256i vb${N} = _mm256_loadu_si256((const __m256i*) (b + ${N}));
        $for N in range(0, NR, 8):
          _mm256_storeu_si256((__m256i*) (out + ${N*4}), vb${N});
        b += ${NR};
      } else {
        $for N in range(0, NR, 8):
          _mm256_storeu_si256((__m256i*) (out + ${N*4}), _mm256_setzero_si256());
      }
      out += ${NR} * sizeof(${BTYPE});

      $if PREFETCH:
        $for N in range(0, NR):
          $for OFFSET in range(0, 448, 64):
            xnn_prefetch_to_l1((const int8_t*) w${N} + ${OFFSET});

      $if DATATYPE in ["QS8"]:
        $for N in range(0, NR, 8):
          __m256i vacc${N} = _mm256_setzero_si256();

      size_t k = kc;
      $if UNROLL:
        // KC main loop multiple of ${NR}x${8 * KR}
        for (; k >= ${8 * KR}; k -= ${8 * KR}) {
          $for N in range(NR):
            const __m256i v${N}_01234567 = _mm256_loadu_si256((const __m256i*) w${N});

          $for N in range(0, NR, 2):
            const __m256i v${N}${N+1}_0145 = _mm256_unpacklo_epi32(v${N}_01234567, v${N+1}_01234567);
            const __m256i v${N}${N+1}_2367 = _mm256_unpackhi_epi32(v${N}_01234567, v${N+1}_01234567);

          $for N in range(0, NR, 4):
            const __m256i v${N}${N+2}_02 = _mm256_unpacklo_epi64(v${N}${N+1}_0145, v${N+2}${N+3}_0145);
            const __m256i v${N}${N+2}_13 = _mm256_unpackhi_epi64(v${N}${N+1}_0145, v${N+2}${N+3}_0145);
            const __m256i v${N+1}${N+3}_02 = _mm256_unpacklo_epi64(v${N}${N+1}_2367, v${N+2}${N+3}_2367);
            const __m256i v${N+1}${N+3}_13 = _mm256_unpackhi_epi64(v${N}${N+1}_2367, v${N+2}${N+3}_2367);

         $for N in range(0, NR // 4):
           $for I in range(0, 2):
             $C = N*2+I
             const __m256i v${C}${C+4}_0 = _mm256_permute2f128_si256(v${N}${N+2}_${I}${I+2}, v${N+4}${N+6}_${I}${I+2}, _MM_SHUFFLE(0, 2, 0, 0));
             const __m256i v${C}${C+4}_1 = _mm256_permute2f128_si256(v${N}${N+2}_${I}${I+2}, v${N+4}${N+6}_${I}${I+2}, _MM_SHUFFLE(0, 3, 0, 1));

          $if PREFETCH:
            $for N in range(0, NR):
              xnn_prefetch_to_l1((const int8_t*) w${N} + 448);

          $if DATATYPE in ["QS8"]:
            $for N in range(0, NR, 8):
              $for I in range(0, 2):
                $for J in range(0, 4):
                  vacc${N} = ${_MM256_DPBUSD_EPI32}(vacc${N}, vone, v${J}${J+4}_${I});

          $for I in range(0, 2):
            $for N in range(0, KR):
              _mm256_storeu_si256((__m256i *)&out[${(I*KR + N)*8*KR}],  v${N}${N+4}_${I});

          $for N in range(NR):
            w${N} += ${8 * KR};
          out += ${8*NR*KR};
        }

      // KC main loop multiple of ${NR}x${KR}
      for (; k >= ${KR}; k -= ${KR}) {
        $for N in range(0, NR, 8):
          __m256i v${N} = _mm256_set1_epi32((int32_t) unaligned_load_u32(w${N}));
          v${N} = _mm256_blend_epi32(v${N}, _mm256_set1_epi32((int32_t) unaligned_load_u32(w${N+1})), 0x02);
          v${N} = _mm256_blend_epi32(v${N}, _mm256_set1_epi32((int32_t) unaligned_load_u32(w${N+2})), 0x04);
          v${N} = _mm256_blend_epi32(v${N}, _mm256_set1_epi32((int32_t) unaligned_load_u32(w${N+3})), 0x08);
          v${N} = _mm256_blend_epi32(v${N}, _mm256_set1_epi32((int32_t) unaligned_load_u32(w${N+4})), 0x10);
          v${N} = _mm256_blend_epi32(v${N}, _mm256_set1_epi32((int32_t) unaligned_load_u32(w${N+5})), 0x20);
          v${N} = _mm256_blend_epi32(v${N}, _mm256_set1_epi32((int32_t) unaligned_load_u32(w${N+6})), 0x40);
          v${N} = _mm256_blend_epi32(v${N}, _mm256_set1_epi32((int32_t) unaligned_load_u32(w${N+7})), 0x80);
        $if PREFETCH:
          $for N in range(0, NR):
            xnn_prefetch_to_l1((const int8_t*) w${N} + 448);

        $if DATATYPE in ["QS8"]:
          $for N in range(0, NR, 8):
            vacc${N} = ${_MM256_DPBUSD_EPI32}(vacc${N}, vone, v${N});
        $elif DATATYPE in ["QS4"]:
          $for N in range(0, NR, 8):
            v${N} = _mm256_xor_si256(v${N}, vkernel_zero_point);    // uint4 -> int4
            v${N} = xnn_packed2planar(&vacc${N}, v${N}, vmask, vone);

        $for N in range(0, NR, 8):
          _mm256_storeu_si256((__m256i *)&out[${N * KR}],  v${N});

        $for N in range(NR):
          w${N} += ${KR};
        out += ${NR*KR};
      }

      // KC remainder of 1..${KR-1}
      if (k != 0) {
        assert(k >= 1 && k <= ${KR-1});

        $for N in range(0, NR, 8):
          __m256i v${N} = _mm256_set1_epi32((int32_t) safe_load_u32(w${N}, k));
          v${N} = _mm256_blend_epi32(v${N}, _mm256_set1_epi32((int32_t) safe_load_u32(w${N+1}, k)), 0x02);
          v${N} = _mm256_blend_epi32(v${N}, _mm256_set1_epi32((int32_t) safe_load_u32(w${N+2}, k)), 0x04);
          v${N} = _mm256_blend_epi32(v${N}, _mm256_set1_epi32((int32_t) safe_load_u32(w${N+3}, k)), 0x08);
          v${N} = _mm256_blend_epi32(v${N}, _mm256_set1_epi32((int32_t) safe_load_u32(w${N+4}, k)), 0x10);
          v${N} = _mm256_blend_epi32(v${N}, _mm256_set1_epi32((int32_t) safe_load_u32(w${N+5}, k)), 0x20);
          v${N} = _mm256_blend_epi32(v${N}, _mm256_set1_epi32((int32_t) safe_load_u32(w${N+6}, k)), 0x40);
          v${N} = _mm256_blend_epi32(v${N}, _mm256_set1_epi32((int32_t) safe_load_u32(w${N+7}, k)), 0x80);

        $for N in range(NR):
          w${N} += k;

        $if PREFETCH:
          $for N in range(0, NR):
            xnn_prefetch_to_l1((const int8_t*) w${N} + 448);

        $if DATATYPE in ["QS8"]:
          $for N in range(0, NR, 8):
            vacc${N} = ${_MM256_DPBUSD_EPI32}(vacc${N}, vone, v${N});
        $elif DATATYPE in ["QS4"]:
          $for N in range(0, NR, 8):
            v${N} = _mm256_xor_si256(v${N}, vkernel_zero_point);    // uint4 -> int4
            v${N} = xnn_packed2planar(&vacc${N}, v${N}, vmask, vone);

        $for N in range(0, NR, 8):
          _mm256_storeu_si256((__m256i *)&out[${N * KR}],  v${N});

        out += ${NR*KR};
      }

      $if DATATYPE in ["QS8"]:
        $for N in range(0, NR, 8):
          __m256i vksum${N} = _mm256_mullo_epi32(vacc${N}, vzeropoint);
        $for N in range(0, NR, 8):
          __m256i vpack${N} =  _mm256_loadu_si256((const __m256i*) (packed_b + ${N}));
        $for N in range(0, NR, 8):
          vpack${N} = _mm256_sub_epi32(vpack${N}, vksum${N});
        $for N in range(0, NR, 8):
          _mm256_storeu_si256((__m256i *) (packed_b + ${N}), vpack${N});
      out = (${TYPE}*) ((uintptr_t) out + extra_bytes);
      w0 = w${NR-1};
    }

    // NC remainder (1..${NR-1})
    if XNN_UNLIKELY(n != 0) {
      assert(n >= 1 && n <= ${NR-1});

      $if DATATYPE in ["QS8", "QS4"]:
        ${BTYPE}* packed_b = (${BTYPE}*) out;
      if XNN_LIKELY(b != NULL) {
        size_t nb = n;
        for (nb = 0; nb < n; ++nb) {
          ((${BTYPE}*) out)[nb] = b[nb];
        }
        b += n;
      } else {
        $for N in range(0, NR, 8):
          _mm256_storeu_si256((__m256i*) (out + ${N*4}), _mm256_setzero_si256());
      }
      out += ${NR} * sizeof(${BTYPE});

      $for N in range(1, NR):
        const ${TYPE}* w${N} = w${N-1} + kc;
        $if N % 2 == 0:
          if XNN_UNPREDICTABLE(n <= ${N}) {
            w${N} = w${N-1};
          }
        $else:
          if XNN_UNPREDICTABLE(n < ${N+1}) {
            w${N} = w${N-1};
          }

      $if DATATYPE in ["QS8"]:
        $for N in range(0, NR, 8):
          __m256i vacc${N} = _mm256_setzero_si256();

      size_t k = kc;
      // KC main loop multiple of ${NR}x${KR}
      for (; k >= ${KR}; k -= ${KR}) {
        $for N in range(0, NR, 8):
          __m256i v${N} = _mm256_set1_epi32((int32_t) unaligned_load_u32(w${N}));
          v${N} = _mm256_blend_epi32(v${N}, _mm256_set1_epi32((int32_t) unaligned_load_u32(w${N+1})), 0x02);
          v${N} = _mm256_blend_epi32(v${N}, _mm256_set1_epi32((int32_t) unaligned_load_u32(w${N+2})), 0x04);
          v${N} = _mm256_blend_epi32(v${N}, _mm256_set1_epi32((int32_t) unaligned_load_u32(w${N+3})), 0x08);
          v${N} = _mm256_blend_epi32(v${N}, _mm256_set1_epi32((int32_t) unaligned_load_u32(w${N+4})), 0x10);
          v${N} = _mm256_blend_epi32(v${N}, _mm256_set1_epi32((int32_t) unaligned_load_u32(w${N+5})), 0x20);
          v${N} = _mm256_blend_epi32(v${N}, _mm256_set1_epi32((int32_t) unaligned_load_u32(w${N+6})), 0x40);
          v${N} = _mm256_blend_epi32(v${N}, _mm256_set1_epi32((int32_t) unaligned_load_u32(w${N+7})), 0x80);
        $if PREFETCH:
          $for N in range(0, NR):
            xnn_prefetch_to_l1((const int8_t*) w${N} + 448);

        $if DATATYPE in ["QS8"]:
          $for N in range(0, NR, 8):
            vacc${N} = ${_MM256_DPBUSD_EPI32}(vacc${N}, vone, v${N});
        $elif DATATYPE in ["QS4"]:
          $for N in range(0, NR, 8):
            v${N} = _mm256_xor_si256(v${N}, vkernel_zero_point);    // uint4 -> int4
            v${N} = xnn_packed2planar(&vacc${N}, v${N}, vmask, vone);

        $for N in range(0, NR, 8):
          _mm256_storeu_si256((__m256i *)&out[${N * KR}],  v${N});

        $for N in range(NR):
          w${N} += ${KR};
        out += ${NR*KR};
      }

      // KC remainder of 1..${KR-1}
      if (k != 0) {
        assert(k >= 1 && k <= ${KR-1});

        $for N in range(0, NR, 8):
          __m256i v${N} = _mm256_set1_epi32((int32_t) safe_load_u32(w${N}, k));
          v${N} = _mm256_blend_epi32(v${N}, _mm256_set1_epi32((int32_t) safe_load_u32(w${N+1}, k)), 0x02);
          v${N} = _mm256_blend_epi32(v${N}, _mm256_set1_epi32((int32_t) safe_load_u32(w${N+2}, k)), 0x04);
          v${N} = _mm256_blend_epi32(v${N}, _mm256_set1_epi32((int32_t) safe_load_u32(w${N+3}, k)), 0x08);
          v${N} = _mm256_blend_epi32(v${N}, _mm256_set1_epi32((int32_t) safe_load_u32(w${N+4}, k)), 0x10);
          v${N} = _mm256_blend_epi32(v${N}, _mm256_set1_epi32((int32_t) safe_load_u32(w${N+5}, k)), 0x20);
          v${N} = _mm256_blend_epi32(v${N}, _mm256_set1_epi32((int32_t) safe_load_u32(w${N+6}, k)), 0x40);
          v${N} = _mm256_blend_epi32(v${N}, _mm256_set1_epi32((int32_t) safe_load_u32(w${N+7}, k)), 0x80);

        $for N in range(NR):
          w${N} += k;

        $if PREFETCH:
          $for N in range(0, NR):
            xnn_prefetch_to_l1((const int8_t*) w${N} + 448);

        $if DATATYPE in ["QS8"]:
          $for N in range(0, NR, 8):
            vacc${N} = ${_MM256_DPBUSD_EPI32}(vacc${N}, vone, v${N});
        $elif DATATYPE in ["QS4"]:
          $for N in range(0, NR, 8):
            v${N} = _mm256_xor_si256(v${N}, vkernel_zero_point);    // uint4 -> int4
            v${N} = xnn_packed2planar(&vacc${N}, v${N}, vmask, vone);

        $for N in range(0, NR, 8):
          _mm256_storeu_si256((__m256i *)&out[${N * KR}],  v${N});

        out += ${NR*KR};
      }

      $if DATATYPE in ["QS8"]:
        $for N in range(0, NR, 8):
          __m256i vksum${N} = _mm256_mullo_epi32(vacc${N}, vzeropoint);
        $for N in range(0, NR, 8):
          __m256i vpack${N} =  _mm256_loadu_si256((const __m256i*) (packed_b + ${N}));
        $for N in range(0, NR, 8):
          vpack${N} = _mm256_sub_epi32(vpack${N}, vksum${N});
        $for N in range(0, NR, 8):
          _mm256_storeu_si256((__m256i *) (packed_b + ${N}), vpack${N});
      out = (${TYPE}*) ((uintptr_t) out + extra_bytes);
    }

    weights += nc * kc;
  } while (--g != 0);
}