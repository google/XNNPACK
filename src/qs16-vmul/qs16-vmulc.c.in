// Copyright 2024 Google LLC
//
// This source code is licensed under the BSD-style license found in the
// LICENSE file in the root directory of this source tree.

$ABC = "0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZ"
$BATCH_TILES = tuple(int(bt) for bt in BATCH_TILES.split(","))
$SIMD_SIZE = BATCH_TILES[0]
#include <assert.h>
#include <stddef.h>
#include <stdint.h>

#include "xnnpack/simd/s16-${ARCH}.h"
$if ARCH == 'avx512bw':
    #include "xnnpack/simd/s32-avx512f.h"
    #include "xnnpack/simd/f32-avx512f.h"
$else:
  $if ARCH == 'sse41':
      #include "xnnpack/simd/s32-sse41.h"
      #include "xnnpack/simd/f32-sse2.h"
  $else:
      #include "xnnpack/simd/s32-${ARCH}.h"
      #include "xnnpack/simd/f32-${ARCH}.h"

#include "xnnpack/common.h"
#include "xnnpack/microparams.h"
#include "xnnpack/vunary.h"

$for BATCH_TILE in BATCH_TILES:
  $assert BATCH_TILE % SIMD_SIZE == 0
  $assert BATCH_TILE >= SIMD_SIZE
  $SIMD_TILE = BATCH_TILE // SIMD_SIZE

  void xnn_qs16_vmulc_minmax_fp32_ukernel__${ARCH}_u${BATCH_TILE}(
      size_t batch,
      const int16_t* input_a,
      const int16_t* input_b,
      int16_t* output,
      const union xnn_qs16_mul_minmax_params params[restrict XNN_MIN_ELEMENTS(1)])
  {
    assert(batch != 0);
    assert(batch % sizeof(int16_t) == 0);
    assert(input_b != NULL);
    assert(input_a != NULL);
    assert(output != NULL);
    assert(xnn_simd_size_s16 == ${SIMD_SIZE});

    xnn_simd_s32_t vzero_point_a = xnn_set1_s32(params->qs16_scalar.a_zero_point);
    xnn_simd_s32_t vzero_point_b = xnn_set1_s32(params->qs16_scalar.b_zero_point);
    xnn_simd_s32_t vzero_point_output = xnn_set1_s32(params->qs16_scalar.output_zero_point);

    xnn_simd_f32_t vscale = xnn_set1_f32(params->qs16_scalar.scale);
    xnn_simd_s16_t voutput_min = xnn_set1_s16(params->qs16_scalar.output_min);
    xnn_simd_s16_t voutput_max = xnn_set1_s16(params->qs16_scalar.output_max);

    xnn_simd_s16_t vin2 = xnn_set1_s16(*input_b);
    xnn_simd_s32_t vin2_low = xnn_low_cvt_s16_s32(vin2);
    xnn_simd_s32_t vin2_high = xnn_high_cvt_s16_s32(vin2);
    vin2_low = xnn_sub_s32(vin2_low, vzero_point_b);
    vin2_high = xnn_sub_s32(vin2_high, vzero_point_b);

    $if SIMD_TILE > 1:
      for (; batch >= ${BATCH_TILE} * sizeof(int16_t); batch -= ${BATCH_TILE} * sizeof(int16_t)) {
        xnn_simd_s16_t vin1_${ABC[0]} = xnn_loadu_s16(input_a);
        $for N in range(1, SIMD_TILE):
          xnn_simd_s16_t vin1_${ABC[N]} = xnn_loadu_s16(input_a + ${N} * xnn_simd_size_s16);
        input_a += ${BATCH_TILE};

        $for N in range(0, SIMD_TILE):
          xnn_simd_s32_t vin1_low_${ABC[N]} = xnn_low_cvt_s16_s32(vin1_${ABC[N]});
          xnn_simd_s32_t vin1_high_${ABC[N]} = xnn_high_cvt_s16_s32(vin1_${ABC[N]});
          vin1_low_${ABC[N]} = xnn_sub_s32(vin1_low_${ABC[N]}, vzero_point_a);
          vin1_high_${ABC[N]} = xnn_sub_s32(vin1_high_${ABC[N]}, vzero_point_a);

          xnn_simd_s32_t vy_s32_low_${ABC[N]} = xnn_mul_s32(vin1_low_${ABC[N]}, vin2_low);
          xnn_simd_s32_t vy_s32_high_${ABC[N]} = xnn_mul_s32(vin1_high_${ABC[N]}, vin2_high);

          xnn_simd_f32_t vy_f32_low_scaled_${ABC[N]} = xnn_mul_f32(xnn_cvt_s32_f32(vy_s32_low_${ABC[N]}), vscale);
          xnn_simd_f32_t vy_f32_high_scaled_${ABC[N]} = xnn_mul_f32(xnn_cvt_s32_f32(vy_s32_high_${ABC[N]}), vscale);

          vy_s32_low_${ABC[N]} = xnn_add_s32(xnn_cvt_f32_s32(vy_f32_low_scaled_${ABC[N]}), vzero_point_output);
          vy_s32_high_${ABC[N]} = xnn_add_s32(xnn_cvt_f32_s32(vy_f32_high_scaled_${ABC[N]}), vzero_point_output);

          xnn_simd_s16_t vy_${ABC[N]} = xnn_cvt_s32_s16(vy_s32_low_${ABC[N]}, vy_s32_high_${ABC[N]});
          vy_${ABC[N]} = xnn_max_s16(vy_${ABC[N]}, voutput_min);
          vy_${ABC[N]} = xnn_min_s16(vy_${ABC[N]}, voutput_max);

        xnn_storeu_s16(output, vy_${ABC[0]});
        $for N in range(1, SIMD_TILE):
          xnn_storeu_s16(output + ${N} * xnn_simd_size_s16, vy_${ABC[N]});
        output += ${BATCH_TILE};
      }
    for (; batch >= xnn_simd_bytes_s16; batch -= xnn_simd_bytes_s16) {
      xnn_simd_s16_t vin1 = xnn_loadu_s16(input_a);
      input_a += xnn_simd_size_s16;

      xnn_simd_s32_t vin1_low = xnn_low_cvt_s16_s32(vin1);
      xnn_simd_s32_t vin1_high = xnn_high_cvt_s16_s32(vin1);
      vin1_low = xnn_sub_s32(vin1_low, vzero_point_a);
      vin1_high = xnn_sub_s32(vin1_high, vzero_point_a);

      xnn_simd_s32_t vy_s32_low = xnn_mul_s32(vin1_low, vin2_low);
      xnn_simd_s32_t vy_s32_high = xnn_mul_s32(vin1_high, vin2_high);

      xnn_simd_f32_t vy_f32_low_scaled = xnn_mul_f32(xnn_cvt_s32_f32(vy_s32_low), vscale);
      xnn_simd_f32_t vy_f32_high_scaled = xnn_mul_f32(xnn_cvt_s32_f32(vy_s32_high), vscale);

      vy_s32_low = xnn_add_s32(xnn_cvt_f32_s32(vy_f32_low_scaled), vzero_point_output);
      vy_s32_high = xnn_add_s32(xnn_cvt_f32_s32(vy_f32_high_scaled), vzero_point_output);

      xnn_simd_s16_t vy = xnn_cvt_s32_s16(vy_s32_low, vy_s32_high);
      vy = xnn_max_s16(vy, voutput_min);
      vy = xnn_min_s16(vy, voutput_max);

      xnn_storeu_s16(output, vy);
      output += xnn_simd_size_s16;
    }
    $if SIMD_SIZE > 1:
      if XNN_UNLIKELY(batch != 0) {
        xnn_simd_s16_t vin1 = xnn_load_tail_s16(input_a, batch >> XNN_LOG2_SIZEOF_INT16_T);

        xnn_simd_s32_t vin1_low = xnn_low_cvt_s16_s32(vin1);
        xnn_simd_s32_t vin1_high = xnn_high_cvt_s16_s32(vin1);
        vin1_low = xnn_sub_s32(vin1_low, vzero_point_a);
        vin1_high = xnn_sub_s32(vin1_high, vzero_point_a);

        xnn_simd_s32_t vy_s32_low = xnn_mul_s32(vin1_low, vin2_low);
        xnn_simd_s32_t vy_s32_high = xnn_mul_s32(vin1_high, vin2_high);

        xnn_simd_f32_t vy_f32_low_scaled = xnn_mul_f32(xnn_cvt_s32_f32(vy_s32_low), vscale);
        xnn_simd_f32_t vy_f32_high_scaled = xnn_mul_f32(xnn_cvt_s32_f32(vy_s32_high), vscale);

        vy_s32_low = xnn_add_s32(xnn_cvt_f32_s32(vy_f32_low_scaled), vzero_point_output);
        vy_s32_high = xnn_add_s32(xnn_cvt_f32_s32(vy_f32_high_scaled), vzero_point_output);
        
        xnn_simd_s16_t vy = xnn_cvt_s32_s16(vy_s32_low, vy_s32_high);
        vy = xnn_max_s16(vy, voutput_min);
        vy = xnn_min_s16(vy, voutput_max);

        xnn_store_tail_s16(output, vy, batch >> XNN_LOG2_SIZEOF_INT16_T);
      }
  }