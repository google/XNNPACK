// Copyright 2024 Google LLC
//
// This source code is licensed under the BSD-style license found in the
// LICENSE file in the root directory of this source tree.

$assert CHANNEL_TILE % 16 == 0
$assert CHANNEL_TILE >= 16
$SIMD_TILE = CHANNEL_TILE // 16
$assert ACCUMULATORS <= SIMD_TILE
$import math
$ABC = "0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZ"
#include <assert.h>

#include <arm_neon.h>

#include "xnnpack/common.h"
#include "xnnpack/math.h"
#include "xnnpack/reduce.h"

$ACC_SUFFIX = "" if ACCUMULATORS == 1 else "_acc%d" % ACCUMULATORS
void xnn_qs8_rsum_ukernel__neon_u${CHANNEL_TILE}${ACC_SUFFIX}(
    size_t batch,
    const int8_t* input,
    int32_t* output,
    const union xnn_qs8_rsum_params params[restrict XNN_MIN_ELEMENTS(1)]) XNN_OOB_READS
{
  assert(batch != 0);
  assert(input != NULL);
  assert(output != NULL);
  assert(params != NULL);

  $for A in range(ACCUMULATORS):
    int32x4_t vacc${A} = vmovq_n_s32(0);

  for (; batch >= ${ACCUMULATORS * 128}; batch -= ${ACCUMULATORS * 128}) {
    $for A in range(ACCUMULATORS):
      int16x8_t vacc16_${A} = vmovq_n_s16(0);
    for (size_t current_batch = ${ACCUMULATORS * 128}; current_batch > 0; current_batch -= ${CHANNEL_TILE}) {
      $for N in range(SIMD_TILE):
        const int8x16_t vt${N} = vld1q_s8(input); input += 16;

      $for N in range(SIMD_TILE):
        vacc16_${N % ACCUMULATORS} = vpadalq_s8(vacc16_${N % ACCUMULATORS}, vt${N});
    }
    $for A in range(ACCUMULATORS):
      vacc${A} = vpadalq_s16(vacc${A}, vacc16_${A});
  }

  if (XNN_UNLIKELY(batch != 0)) {
    $for A in range(ACCUMULATORS):
      int16x8_t vacc16_${A} = vmovq_n_s16(0);
    for (; batch >= ${CHANNEL_TILE}; batch -= ${CHANNEL_TILE}) {
      $for N in range(SIMD_TILE):
        const int8x16_t vt${N} = vld1q_s8(input); input += 16;

      $for N in range(SIMD_TILE):
        vacc16_${N % ACCUMULATORS} = vpadalq_s8(vacc16_${N % ACCUMULATORS}, vt${N});
    }
    $if ACCUMULATORS > 1:
      $ACC_SLICE = 1
      $while ACC_SLICE < ACCUMULATORS:
        $for A in range(0, ACCUMULATORS, ACC_SLICE * 2):
          $if A + ACC_SLICE < ACCUMULATORS:
            vacc16_${A} = vaddq_s16(vacc16_${A}, vacc16_${A + ACC_SLICE});
        $ACC_SLICE *= 2
    for (; batch >= 16; batch -= 16) {
      const int8x16_t vt = vld1q_s8(input); input += 16;
      vacc16_0 = vpadalq_s8(vacc16_0, vt);
    }
    if (XNN_UNLIKELY(batch != 0)) {
      const int8x16_t vt = vld1q_s8(input);
      const int8x16_t vmask = vld1q_s8(&params->neon.mask_table[15 - batch]);
      const int8x16_t vtm = vmulq_s8(vt, vmask);
      vacc16_0 = vpadalq_s8(vacc16_0, vtm);
    }
    vacc0 = vpadalq_s16(vacc0, vacc16_0);
  }
  $if ACCUMULATORS > 1:
    $ACC_SLICE = 1
    $while ACC_SLICE < ACCUMULATORS:
      $for A in range(0, ACCUMULATORS, ACC_SLICE * 2):
        $if A + ACC_SLICE < ACCUMULATORS:
          vacc${A} = vaddq_s32(vacc${A}, vacc${A + ACC_SLICE});
      $ACC_SLICE *= 2
  #if XNN_ARCH_ARM64
    const int32_t vacc = vaddvq_s32(vacc0);
  #else
    int32x2_t vacc_lo = vadd_s32(vget_low_s32(vacc0), vget_high_s32(vacc0));
    vacc_lo = vpadd_s32(vacc_lo, vacc_lo);
    const int32_t vacc = vget_lane_s32(vacc_lo, 0);
  #endif

  *output += vacc;
}
