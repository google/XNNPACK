// Copyright 2023 Google LLC
//
// This source code is licensed under the BSD-style license found in the
// LICENSE file in the root directory of this source tree.

$assert SSE == 4
$assert not 0 or AVX
$assert not AVX or SSE == 4
$assert REQUANTIZATION == "FP32"
$assert DATATYPE in ["QC8", "QS8", "QU8"]
$ABC = "0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZ"
$assert CHANNEL_TILE % 8 == 0
$assert CHANNEL_TILE >= 8
$CHANNEL_SUBTILE = 4
$assert CHANNEL_TILE % CHANNEL_SUBTILE == 0
$CHANNEL_ROUND = 4
$assert MIDDLE_PASS_TILE <= LAST_PASS_TILE
$assert FIRST_PASS_TILE >= 1
$assert MIDDLE_PASS_TILE >= 1
$assert LAST_PASS_TILE >= 1
#include <assert.h>

#include <immintrin.h>

#include "xnnpack/dwconv.h"
#include "xnnpack/intrinsics-polyfill.h"
#include "xnnpack/math.h"
#include "xnnpack/unaligned.h"


$DATATYPE_SPEC = {"QS8": "qs8", "QC8": "qs8_qc8w", "QU8": "qu8"}[DATATYPE]
$PARAMS_STRUCT = REQUANTIZATION.lower() + "_" + ("sse2" if DATATYPE == "QU8" else "sse4")
$PARAMS_UNION = "xnn_qs8_qc8w_conv_minmax_params" if DATATYPE == "QC8" else "xnn_%s_conv_minmax_params" % DATATYPE.lower()
$ISA = "avx" if AVX else {4: "sse41"}[SSE]
$XINT8_T = "uint8_t" if DATATYPE == "QU8" else "int8_t"
$_MM_CVTEPX8_EPI32 = "_mm_cvtepu8_epi32" if DATATYPE == "QU8" else "_mm_cvtepi8_epi32"
$_MM_PACKXS_EPI16 = "_mm_packus_epi16" if DATATYPE == "QU8" else "_mm_packs_epi16"
$_MM_MAX_EPX8 = "_mm_max_epu8" if DATATYPE == "QU8" else "_mm_max_epi8"
void xnn_${DATATYPE_SPEC}_dwconv_minmax_${REQUANTIZATION.lower()}_ukernel_${FIRST_PASS_TILE}f${MIDDLE_PASS_TILE}m${LAST_PASS_TILE}l${CHANNEL_TILE}c${CHANNEL_SUBTILE}s${CHANNEL_ROUND}r__${ISA}_mul32(
    size_t channels,
    size_t output_width,
    const ${XINT8_T}** input,
    const void* weights,
    ${XINT8_T}* output,
    intptr_t input_stride,
    size_t output_increment,
    size_t input_offset,
    const ${XINT8_T}* zero,
    size_t kernel_size,
    int32_t* buffer,
    const union ${PARAMS_UNION} params[restrict XNN_MIN_ELEMENTS(1)]) XNN_OOB_READS
{
  assert(channels != 0);
  assert(output_width != 0);
  assert(kernel_size > ${FIRST_PASS_TILE});

  $if DATATYPE == "QU8":
    const __m128i vk_zero_point = _mm_cvtepu16_epi32(_mm_loadl_epi64((const __m128i*) params->${PARAMS_STRUCT}.kernel_zero_point));

  do {
    const void* w = weights;

    // First pass to process ${FIRST_PASS_TILE} inputs.
    {
      int32_t* b = buffer;
      $for K in range(FIRST_PASS_TILE):
        const ${XINT8_T}* i${K} = input[${K}];
        assert(i${K} != NULL);
        if XNN_UNPREDICTABLE(i${K} != zero) {
          i${K} = (const ${XINT8_T}*) ((uintptr_t) i${K} + input_offset);
        }
      input += ${FIRST_PASS_TILE};

      size_t c = round_up_po2(channels, ${CHANNEL_ROUND});

      for (; c >= ${CHANNEL_TILE}; c -= ${CHANNEL_TILE}) {
        __m128i vacc${ABC[0:4]} = _mm_loadu_si128((const __m128i*) w);
        $for C in range(4, CHANNEL_TILE, 4):
          __m128i vacc${ABC[C:C+4]} = _mm_loadu_si128((const __m128i*) ((const int32_t*) w + ${C}));

        $for K in range(FIRST_PASS_TILE):

          $for C in range(0, CHANNEL_TILE, 4):
            $if C == 0:
              const __m128i vi${K}x${ABC[0:4]} = ${_MM_CVTEPX8_EPI32}(_mm_cvtsi32_si128((int) unaligned_load_s32(i${K})));
            $else:
              const __m128i vi${K}x${ABC[C:C+4]} = ${_MM_CVTEPX8_EPI32}(_mm_cvtsi32_si128((int) unaligned_load_s32(i${K} + ${C})));
            $if DATATYPE == "QU8":
              const __m128i vk${K}x${ABC[C:C+4]} = _mm_sub_epi32(${_MM_CVTEPX8_EPI32}(_mm_cvtsi32_si128(*((const int*) ((uintptr_t) w + ${CHANNEL_TILE} * sizeof(int32_t) + ${K * CHANNEL_TILE + C} * sizeof(${XINT8_T}))))), vk_zero_point);
            $else:
              const __m128i vk${K}x${ABC[C:C+4]} = ${_MM_CVTEPX8_EPI32}(_mm_cvtsi32_si128(*((const int*) ((uintptr_t) w + ${CHANNEL_TILE} * sizeof(int32_t) + ${K * CHANNEL_TILE + C} * sizeof(${XINT8_T})))));
          i${K} += ${CHANNEL_TILE};

          $for C in range(0, CHANNEL_TILE, 4):
            vacc${ABC[C:C+4]} = _mm_add_epi32(vacc${ABC[C:C+4]}, _mm_mullo_epi32(vi${K}x${ABC[C:C+4]}, vk${K}x${ABC[C:C+4]}));

        w = (const void*) ((uintptr_t) w + ${CHANNEL_TILE} * sizeof(int32_t) + ${FIRST_PASS_TILE * CHANNEL_TILE} * sizeof(${XINT8_T}));

        $for C in range(0, CHANNEL_TILE, 4):
          $if C == 0:
            _mm_storeu_si128((__m128i*) b, vacc${ABC[C:C+4]});
          $else:
            _mm_storeu_si128((__m128i*) (b + ${C}), vacc${ABC[C:C+4]});
        b += ${CHANNEL_TILE};
      }

      $if CHANNEL_TILE == 4:
          assert(c == 0);
      $else:
        if XNN_UNLIKELY(c != 0) {
          ${"do " if CHANNEL_TILE > 4 else ""}{
            __m128i vacc${ABC[0:4]} = _mm_loadu_si128((const __m128i*) w);
            $for K in range(FIRST_PASS_TILE):

              const __m128i vi${K}x${ABC[0:4]} = ${_MM_CVTEPX8_EPI32}(_mm_cvtsi32_si128((int) unaligned_load_s32(i${K})));
              $if DATATYPE == "QU8":
                $if K == 0:
                  const __m128i vk${K}x${ABC[0:4]} = _mm_sub_epi32(${_MM_CVTEPX8_EPI32}(_mm_cvtsi32_si128(*((const int32_t*) ((uintptr_t) w + sizeof(int32_t) * ${CHANNEL_SUBTILE})))), vk_zero_point);
                $else:
                  const __m128i vk${K}x${ABC[0:4]} = _mm_sub_epi32(${_MM_CVTEPX8_EPI32}(_mm_cvtsi32_si128(*((const int32_t*) ((uintptr_t) w + sizeof(int32_t) * ${CHANNEL_SUBTILE} + ${K * CHANNEL_SUBTILE} * sizeof(${XINT8_T}))))), vk_zero_point);
              $else:
                $if K == 0:
                  const __m128i vk${K}x${ABC[0:4]} = ${_MM_CVTEPX8_EPI32}(_mm_cvtsi32_si128(*((const int32_t*) ((uintptr_t) w + ${CHANNEL_SUBTILE} * sizeof(int32_t)))));
                $else:
                  const __m128i vk${K}x${ABC[0:4]} = ${_MM_CVTEPX8_EPI32}(_mm_cvtsi32_si128(*((const int32_t*) ((uintptr_t) w + ${CHANNEL_SUBTILE} * sizeof(int32_t) + ${K * CHANNEL_SUBTILE} * sizeof(${XINT8_T})))));
              $if CHANNEL_TILE > 4:
                i${K} += 4;

              vacc${ABC[0:4]} = _mm_add_epi32(vacc${ABC[0:4]}, _mm_mullo_epi32(vi${K}x${ABC[0:4]}, vk${K}x${ABC[0:4]}));

            w = (const void*) ((uintptr_t) w + ${CHANNEL_SUBTILE} * sizeof(int32_t) + ${FIRST_PASS_TILE * CHANNEL_SUBTILE} * sizeof(${XINT8_T}));

            _mm_storeu_si128((__m128i*) b, vacc0123);
            b += 4;
            c -= 4;
          }${" while (c != 0);" if CHANNEL_TILE > 4 else ""}
        }
    }

    // Middle pass to process ${MIDDLE_PASS_TILE} inputs in each iteration.
    for (size_t ks = kernel_size - ${FIRST_PASS_TILE}; ks > ${LAST_PASS_TILE}; ks -= ${MIDDLE_PASS_TILE}) {
      int32_t* b = buffer;
      $for K in range(MIDDLE_PASS_TILE):
        const ${XINT8_T}* i${K} = input[${K}];
        assert(i${K} != NULL);
        if XNN_UNPREDICTABLE(i${K} != zero) {
          i${K} = (const ${XINT8_T}*) ((uintptr_t) i${K} + input_offset);
        }
      input += ${MIDDLE_PASS_TILE};

      size_t c = round_up_po2(channels, ${CHANNEL_ROUND});

      for (; c >= ${CHANNEL_TILE}; c -= ${CHANNEL_TILE}) {
        __m128i vacc${ABC[0:4]} = _mm_loadu_si128((const __m128i*) b);
        $for C in range(4, CHANNEL_TILE, 4):
          __m128i vacc${ABC[C:C+4]} = _mm_loadu_si128((const __m128i*) (b + ${C}));

        $for K in range(MIDDLE_PASS_TILE):

          $for C in range(0, CHANNEL_TILE, 4):
            $if C == 0:
              const __m128i vi${K}x${ABC[0:4]} = ${_MM_CVTEPX8_EPI32}(_mm_cvtsi32_si128((int) unaligned_load_s32(i${K})));
            $else:
              const __m128i vi${K}x${ABC[C:C+4]} = ${_MM_CVTEPX8_EPI32}(_mm_cvtsi32_si128((int) unaligned_load_s32(i${K} + ${C})));
            $if DATATYPE == "QU8":
              const __m128i vk${K}x${ABC[C:C+4]} = _mm_sub_epi32(${_MM_CVTEPX8_EPI32}(_mm_cvtsi32_si128(*((const int*) ((uintptr_t) w + ${K * CHANNEL_TILE + C} * sizeof(${XINT8_T}))))), vk_zero_point);
            $else:
              const __m128i vk${K}x${ABC[C:C+4]} = ${_MM_CVTEPX8_EPI32}(_mm_cvtsi32_si128(*((const int*) ((uintptr_t) w + ${K * CHANNEL_TILE + C} * sizeof(${XINT8_T})))));
          i${K} += ${CHANNEL_TILE};

          $for C in range(0, CHANNEL_TILE, 4):
            vacc${ABC[C:C+4]} = _mm_add_epi32(vacc${ABC[C:C+4]}, _mm_mullo_epi32(vi${K}x${ABC[C:C+4]}, vk${K}x${ABC[C:C+4]}));

        w = (const void*) ((uintptr_t) w + ${MIDDLE_PASS_TILE * CHANNEL_TILE} * sizeof(${XINT8_T}));

        $for C in range(0, CHANNEL_TILE, 4):
          $if C == 0:
            _mm_storeu_si128((__m128i*) b, vacc${ABC[C:C+4]});
          $else:
            _mm_storeu_si128((__m128i*) (b + ${C}), vacc${ABC[C:C+4]});
        b += ${CHANNEL_TILE};
      }

      $if CHANNEL_TILE == 4:
          assert(c == 0);
      $else:
        if XNN_UNLIKELY(c != 0) {
          ${"do " if CHANNEL_TILE > 4 else ""}{
            __m128i vacc${ABC[0:4]} = _mm_loadu_si128((const __m128i*) b);
            $for K in range(MIDDLE_PASS_TILE):

              const __m128i vi${K}x${ABC[0:4]} = ${_MM_CVTEPX8_EPI32}(_mm_cvtsi32_si128((int) unaligned_load_s32(i${K})));
              $if DATATYPE == "QU8":
                $if K == 0:
                  const __m128i vk${K}x${ABC[0:4]} = _mm_sub_epi32(${_MM_CVTEPX8_EPI32}(_mm_cvtsi32_si128(*((const int32_t*) ((uintptr_t) w)))), vk_zero_point);
                $else:
                  const __m128i vk${K}x${ABC[0:4]} = _mm_sub_epi32(${_MM_CVTEPX8_EPI32}(_mm_cvtsi32_si128(*((const int32_t*) ((uintptr_t) w + ${K * CHANNEL_SUBTILE} * sizeof(${XINT8_T}))))), vk_zero_point);
              $else:
                $if K == 0:
                  const __m128i vk${K}x${ABC[0:4]} = ${_MM_CVTEPX8_EPI32}(_mm_cvtsi32_si128(*((const int32_t*) ((uintptr_t) w))));
                $else:
                  const __m128i vk${K}x${ABC[0:4]} = ${_MM_CVTEPX8_EPI32}(_mm_cvtsi32_si128(*((const int32_t*) ((uintptr_t) w + ${K * CHANNEL_SUBTILE} * sizeof(${XINT8_T})))));
              $if CHANNEL_TILE > 4:
                i${K} += 4;

              vacc${ABC[0:4]} = _mm_add_epi32(vacc${ABC[0:4]}, _mm_mullo_epi32(vi${K}x${ABC[0:4]}, vk${K}x${ABC[0:4]}));

            w = (const void*) ((uintptr_t) w + ${MIDDLE_PASS_TILE * CHANNEL_SUBTILE} * sizeof(${XINT8_T}));

            _mm_storeu_si128((__m128i*) b, vacc0123);
            b += 4;
            c -= 4;
          }${" while (c != 0);" if CHANNEL_TILE > 4 else ""}
        }
    }

    // Last pass to process up to ${LAST_PASS_TILE} inputs.
    {
      const int32_t* b = buffer;
      $for K in range(LAST_PASS_TILE):
        const ${XINT8_T}* i${K} = input[${K}];
        assert(i${K} != NULL);
        if XNN_UNPREDICTABLE(i${K} != zero) {
          i${K} = (const ${XINT8_T}*) ((uintptr_t) i${K} + input_offset);
        }

      size_t c = channels;

      for (; c >= ${CHANNEL_TILE}; c -= ${CHANNEL_TILE}) {
        __m128i vacc${ABC[0:4]} = _mm_loadu_si128((const __m128i*) b);
        $for C in range(4, CHANNEL_TILE, 4):
          __m128i vacc${ABC[C:C+4]} = _mm_loadu_si128((const __m128i*) (b + ${C}));
        b += ${CHANNEL_TILE};

        $for K in range(LAST_PASS_TILE):

          $for C in range(0, CHANNEL_TILE, 4):
            $if C == 0:
              const __m128i vi${K}x${ABC[0:4]} = ${_MM_CVTEPX8_EPI32}(_mm_cvtsi32_si128((int) unaligned_load_s32(i${K})));
            $else:
              const __m128i vi${K}x${ABC[C:C+4]} = ${_MM_CVTEPX8_EPI32}(_mm_cvtsi32_si128((int) unaligned_load_s32(i${K} + ${C})));
            $if DATATYPE == "QU8":
              const __m128i vk${K}x${ABC[C:C+4]} = _mm_sub_epi32(${_MM_CVTEPX8_EPI32}(_mm_cvtsi32_si128(*((const int*) ((uintptr_t) w + ${K * CHANNEL_TILE + C} * sizeof(${XINT8_T}))))), vk_zero_point);
            $else:
              const __m128i vk${K}x${ABC[C:C+4]} = ${_MM_CVTEPX8_EPI32}(_mm_cvtsi32_si128(*((const int*) ((uintptr_t) w + ${K * CHANNEL_TILE + C} * sizeof(${XINT8_T})))));
          i${K} += ${CHANNEL_TILE};

          $for C in range(0, CHANNEL_TILE, 4):
            vacc${ABC[C:C+4]} = _mm_add_epi32(vacc${ABC[C:C+4]}, _mm_mullo_epi32(vi${K}x${ABC[C:C+4]}, vk${K}x${ABC[C:C+4]}));

        w = (const void*) ((uintptr_t) w + ${LAST_PASS_TILE * CHANNEL_TILE} * sizeof(${XINT8_T}));

        $for C in range(0, CHANNEL_TILE, 4):
          __m128 vscaled${ABC[C:C+4]} = _mm_cvtepi32_ps(vacc${ABC[C:C+4]});

        $if DATATYPE == "QC8":
          const __m128 vscale${ABC[0:4]} = _mm_loadu_ps((const float*) w);
          $for C in range(4, CHANNEL_TILE, 4):
            const __m128 vscale${ABC[C:C+4]} = _mm_loadu_ps((const float*) w + ${C});
          w = (const void*) ((const float*) w + ${CHANNEL_TILE});
          $for C in range(0, CHANNEL_TILE, 4):
            vscaled${ABC[C:C+4]} = _mm_mul_ps(vscaled${ABC[C:C+4]}, vscale${ABC[C:C+4]});
        $else:
          const __m128 vscale = _mm_load_ps(params->${PARAMS_STRUCT}.scale);
          $for C in range(0, CHANNEL_TILE, 4):
            vscaled${ABC[C:C+4]} = _mm_mul_ps(vscaled${ABC[C:C+4]}, vscale);

        const __m128 voutput_max_less_zero_point = _mm_load_ps(params->${PARAMS_STRUCT}.output_max_less_zero_point);
        $for C in range(0, CHANNEL_TILE, 4):
          vscaled${ABC[C:C+4]} = _mm_min_ps(vscaled${ABC[C:C+4]}, voutput_max_less_zero_point);

        $for C in range(0, CHANNEL_TILE, 4):
          vacc${ABC[C:C+4]} = _mm_cvtps_epi32(vscaled${ABC[C:C+4]});

        const __m128i voutput_zero_point = _mm_load_si128((const __m128i*) params->${PARAMS_STRUCT}.output_zero_point);
        $for C in range(0, CHANNEL_TILE, 8):
          __m128i vout${ABC[C:C+8]} = _mm_adds_epi16(_mm_packs_epi32(vacc${ABC[C:C+4]}, vacc${ABC[C+4:C+8]}), voutput_zero_point);

        const __m128i voutput_min = _mm_load_si128((const __m128i*) params->${PARAMS_STRUCT}.output_min);
        $for C in range(0, CHANNEL_TILE, 16):
          $if C + 8 < CHANNEL_TILE:
            __m128i vout${ABC[C:C+16]} = ${_MM_PACKXS_EPI16}(vout${ABC[C:C+8]}, vout${ABC[C+8:C+16]});
            vout${ABC[C:C+16]} = ${_MM_MAX_EPX8}(vout${ABC[C:C+16]}, voutput_min);
          $else:
            __m128i vout${ABC[C:C+8]}${ABC[C:C+8]} = ${_MM_PACKXS_EPI16}(vout${ABC[C:C+8]}, vout${ABC[C:C+8]});
            vout${ABC[C:C+8]}${ABC[C:C+8]} = ${_MM_MAX_EPX8}(vout${ABC[C:C+8]}${ABC[C:C+8]}, voutput_min);

        $if CHANNEL_TILE > 8:
          _mm_storeu_si128((__m128i*) output, vout${ABC[0:16]});
        $else:
          _mm_storel_epi64((__m128i*) output, vout${ABC[0:8]}${ABC[0:8]});
        $for C in range(16, CHANNEL_TILE, 16):
          $if C + 8 < CHANNEL_TILE:
            _mm_storeu_si128((__m128i*) (output + ${C}), vout${ABC[C:C+16]});
          $else:
            _mm_storel_epi64((__m128i*) (output + ${C}), vout${ABC[C:C+8]}${ABC[C:C+8]});
        output += ${CHANNEL_TILE};
      }

      if XNN_UNLIKELY(c != 0) {
        ${"do " if CHANNEL_TILE > 4 else ""}{
          __m128i vacc${ABC[0:4]} = _mm_loadu_si128((const __m128i*) b);
          b += 4;
          $for K in range(LAST_PASS_TILE):

            const __m128i vi${K}x${ABC[0:4]} = ${_MM_CVTEPX8_EPI32}(_mm_cvtsi32_si128((int) unaligned_load_s32(i${K})));
            $if DATATYPE == "QU8":
              const __m128i vk${K}x${ABC[0:4]} = _mm_sub_epi32(${_MM_CVTEPX8_EPI32}(_mm_cvtsi32_si128(*((const int*) ((uintptr_t) w + ${K * CHANNEL_SUBTILE} * sizeof(${XINT8_T}))))), vk_zero_point);
            $else:
              const __m128i vk${K}x${ABC[0:4]} = ${_MM_CVTEPX8_EPI32}(_mm_cvtsi32_si128(*((const int*) ((uintptr_t) w + ${K * CHANNEL_SUBTILE} * sizeof(${XINT8_T})))));
            $if CHANNEL_TILE > 4:
              i${K} += 4;

            vacc${ABC[0:4]} = _mm_add_epi32(vacc${ABC[0:4]}, _mm_mullo_epi32(vi${K}x${ABC[0:4]}, vk${K}x${ABC[0:4]}));

          __m128 vscaled${ABC[0:4]} = _mm_cvtepi32_ps(vacc${ABC[0:4]});
          $if DATATYPE == "QC8":
            const __m128 vscale${ABC[0:4]} = _mm_loadu_ps((const float*) ((uintptr_t) w + ${CHANNEL_SUBTILE * LAST_PASS_TILE} * sizeof(${XINT8_T})));
            vscaled${ABC[0:4]} = _mm_mul_ps(vscaled${ABC[0:4]}, vscale${ABC[0:4]});
          $else:
            vscaled${ABC[0:4]} = _mm_mul_ps(vscaled${ABC[0:4]}, _mm_load_ps(params->${PARAMS_STRUCT}.scale));
          vscaled${ABC[0:4]} = _mm_min_ps(vscaled${ABC[0:4]}, _mm_load_ps(params->${PARAMS_STRUCT}.output_max_less_zero_point));
          vacc${ABC[0:4]} = _mm_cvtps_epi32(vscaled${ABC[0:4]});

          $if CHANNEL_TILE > 4:
            $if DATATYPE == "QC8":
              w = (void*) ((uintptr_t) w + ${LAST_PASS_TILE * CHANNEL_SUBTILE} + 4 * sizeof(float));
            $else:
              w = (void*) ((uintptr_t) w + ${LAST_PASS_TILE * CHANNEL_SUBTILE} * sizeof(${XINT8_T}));

          const __m128i voutput_zero_point = _mm_load_si128((const __m128i*) params->${PARAMS_STRUCT}.output_zero_point);
          __m128i vout${ABC[0:4]} = _mm_adds_epi16(_mm_packs_epi32(vacc${ABC[0:4]}, vacc${ABC[0:4]}), voutput_zero_point);

          vout${ABC[0:4]} = ${_MM_PACKXS_EPI16}(vout${ABC[0:4]}, vout${ABC[0:4]});
          vout${ABC[0:4]} = ${_MM_MAX_EPX8}(vout${ABC[0:4]}, _mm_load_si128((const __m128i*) params->${PARAMS_STRUCT}.output_min));

          $if CHANNEL_TILE > 4:
            if XNN_LIKELY(c >= 4) {
              _mm_storeu_si32(output, vout${ABC[0:4]});
              output += 4;
              c -= 4;
            } else {
              if (c & 2) {
                unaligned_store_u16(output, (uint16_t) _mm_extract_epi16(vout${ABC[0:4]}, 0));
                vout${ABC[0:4]} = _mm_srli_epi32(vout${ABC[0:4]}, 16);
                output += 2;
              }
              if (c & 1) {
                *output = (${XINT8_T}) _mm_extract_epi8(vout${ABC[0:4]}, 0);
                output += 1;
              }
              c = 0;
            }
          $else:
            if (c & 2) {
              unaligned_store_u16(output, (uint16_t) _mm_extract_epi16(vout${ABC[0:4]}, 0));
              vout${ABC[0:4]} = _mm_srli_epi32(vout${ABC[0:4]}, 16);
              output += 2;
            }
            if (c & 1) {
              *output = (${XINT8_T}) _mm_extract_epi8(vout${ABC[0:4]}, 0);
              output += 1;
            }
        }${" while (c != 0);" if CHANNEL_TILE > 4 else ""}
      }
    }

    input = (const ${XINT8_T}**) ((uintptr_t) input + input_stride);
    output = (${XINT8_T}*) ((uintptr_t) output + output_increment);
  } while (--output_width != 0);
}
