// Copyright 2024 Google LLC
//
// This source code is licensed under the BSD-style license found in the
// LICENSE file in the root directory of this source tree.

$ABC = "0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZ"
$assert REQUANTIZATION == "FP32" or not REQUANTIZATION
$assert DATATYPE in ["QD8_F32", "QC8"]
$assert ACCUMULATORS == 1 or ACCUMULATORS == 2
#include <assert.h>

#include <immintrin.h>

#include <xnnpack/gemm.h>
#include <xnnpack/intrinsics-polyfill.h>
#include <xnnpack/math.h>
#include <xnnpack/unaligned.h>
$if PREFETCH:
  #include <xnnpack/prefetch.h>

// Define tile config data structure
typedef struct __tile_config {
  uint8_t palette_id;
  uint8_t start_row;
  uint8_t reserved_0[14];
  uint16_t colsb[8];
  uint16_t reserved_1[8];
  uint8_t rows[8];
  uint8_t reserved_2[8];
} __tilecfg;

$DATATYPE_SPEC = {"QC8": "qs8_qc8w", "QD8_F32": "qd8_f32_qc8w", "QC4_F32": "qd8_f32_qc4w"}[DATATYPE]
$REQUANTIZATION_SPEC = "" if DATATYPE in ["QD8_F32", "QC4_F32"] else "_" + REQUANTIZATION.lower()
$PARAMS_STRUCT = REQUANTIZATION.lower() + "_avx512"
$PARAMS_UNION = {"QC8": "xnn_qs8_qc8w_conv_minmax_params", "QD8_F32": "xnn_f32_minmax_params", "QC4_F32": "xnn_f32_qc4w_minmax_params"}[DATATYPE]
$XINT8_T = "int8_t"
$OUT_T = "float" if DATATYPE in ["QD8_F32", "QC4_F32"] else XINT8_T
$_MM_MAX_EPX8 = "_mm_max_epi8"
$_MM512_CVTXEPI32_EPI8 = "_mm512_cvtsepi32_epi8"
$ACC_POSTFIX=f"_acc{ACCUMULATORS}" if ACCUMULATORS > 1 else ""
void xnn_${DATATYPE_SPEC}_gemm_minmax${REQUANTIZATION_SPEC}_ukernel_${MR}x16c4__avx512amx${ACC_POSTFIX}${"_prfm" if PREFETCH else ""}(
    size_t mr,
    size_t nc,
    size_t kc,
    const ${XINT8_T}* restrict a,
    size_t a_stride,
    const void* restrict w,
    ${OUT_T}* restrict c,
    size_t cm_stride,
    size_t cn_stride,
    $if DATATYPE in ["QD8_F32", "QC4_F32"]:
      const union ${PARAMS_UNION} params[restrict XNN_MIN_ELEMENTS(1)],
      const struct xnn_qd8_quantization_params quantization_params[restrict XNN_MIN_ELEMENTS(1)])
    $else:
      const union ${PARAMS_UNION} params[restrict XNN_MIN_ELEMENTS(1)])
{
  assert(mr != 0);
  assert(mr <= ${MR});
  assert(nc != 0);
  assert(kc != 0);
  assert(kc % sizeof(${XINT8_T}) == 0);
  assert(a != NULL);
  assert(w != NULL);
  assert(c != NULL);

// TODO: amxintrin.h only provide intrinsics for __x86_64__
// Update if amxintrin changes
#if defined(__x86_64__) && defined(__AMX_TILE__)
  __attribute__((aligned(64))) int32_t res0[${MR} * 16];
  __attribute__((aligned(64))) int32_t res1[${MR} * 16];

  kc = round_up_po2(kc, 4 * sizeof(int8_t));
  size_t kremainder = kc & 63;
  if (kremainder == 0) {  // zero is invalid config
    kremainder = 64;
  }

  // Load tile configuration
  __attribute__((aligned(64))) __tilecfg tile_data = {0};
  tile_data.palette_id = 1;
  tile_data.rows[0] = mr;              // tmm0 = res 0
  tile_data.rows[1] = mr;              // tmm1 = res 1
  tile_data.rows[2] = mr;              // tmm2 = input 0
  tile_data.rows[3] = mr;              // tmm3 = input 1
  tile_data.rows[4] = 16;              // tmm4 = weights 0
  tile_data.rows[5] = 16;              // tmm5 = weights 1
  tile_data.rows[6] = mr;              // tmm6 = input remainder
  tile_data.rows[7] = kremainder >> 2; // tmm7 = weights remainder

  tile_data.colsb[0] = 64;          // tmm0 = res 0
  tile_data.colsb[1] = 64;          // tmm1 = res 1
  tile_data.colsb[2] = 64;          // tmm2 = input 0
  tile_data.colsb[3] = 64;          // tmm3 = input 1
  tile_data.colsb[4] = 64;          // tmm4 = weights 0
  tile_data.colsb[5] = 64;          // tmm5 = weights 1
  tile_data.colsb[6] = kremainder;  // tmm6 = input remainder
  tile_data.colsb[7] = 64;          // tmm7 = weights remainder

  _tile_loadconfig(&tile_data);

  ${OUT_T}* c0 = c;
  $for M in range(1, MR):
    ${OUT_T}* c${M} = (${OUT_T}*) ((uintptr_t) c${M-1} + cm_stride);
    $if M % 2 == 0:
      if XNN_UNPREDICTABLE(mr <= ${M}) {
        c${M} = c${M-1};
      }
    $elif M + 1 == MR:
      if XNN_UNPREDICTABLE(mr != ${M+1}) {
        c${M} = c${M-1};
      }
    $else:
      if XNN_UNPREDICTABLE(mr < ${M+1}) {
        c${M} = c${M-1};
      }

  $if DATATYPE in ["QD8_F16", "QD8_F32", "QC4_F16", "QC4_F32"]:
    const __m512 voutput_min = _mm512_set1_ps(params->scalar.min);
    const __m512 voutput_max = _mm512_set1_ps(params->scalar.max);
    $if DATATYPE in ["QC4_F16", "QC4_F32"]:
      const __m256i vmask = _mm256_set1_epi8(params->scalar.mask);
  $else:
    const __m512 voutput_max_less_zero_point = _mm512_set1_ps(params->${PARAMS_STRUCT}.output_max_less_zero_point);
    const __m512i voutput_zero_point = _mm512_set1_epi32(params->${PARAMS_STRUCT}.output_zero_point);
    const __m128i voutput_min = _mm_load_si128((const __m128i*) params->${PARAMS_STRUCT}.output_min);

  do {
    const __m512i vksum0123456789ABCDEF = _mm512_load_epi32(w);
    w = (const int32_t*) w + 16;

    // Zero tile accumulator
    _tile_zero(0);  // tmm0 is accumulator
    $if ACCUMULATORS > 1:
      _tile_zero(1);  // tmm1 is accumulator 2

    size_t k = kc;
    $if ACCUMULATORS > 1:
      if XNN_UNLIKELY(k >= 128 * sizeof(int8_t)) {
        // Prologue load
        _tile_loadd(2, a, a_stride);
        _tile_loadd(3, a + 64, a_stride);
        _tile_stream_loadd(4, w, 64);
        _tile_stream_loadd(5, (const ${XINT8_T}*) w + 1024, 64);

        a += 128;
        w = (const ${XINT8_T}*) w + 2048;
        k -= 128 * sizeof(${XINT8_T});

        // Process up to 16x128 (2 tiles wide)
        while (k >= 128 * sizeof(int8_t)) {
          // Multiply tiles
          _tile_dpbssd (0, 2, 4);
          _tile_dpbssd (1, 3, 5);
          $if PREFETCH:
            $for P in range(5120, 7168, 64):
              xnn_prefetch_to_l1((const ${XINT8_T}*) w + ${P});

          _tile_loadd(2, a, a_stride);
          _tile_loadd(3, a + 64, a_stride);
          _tile_stream_loadd(4, w, 64);
          _tile_stream_loadd(5, (const ${XINT8_T}*) w + 1024, 64);
          a += 128;
          w = (const ${XINT8_T}*) w + 2048;
          k -= 128 * sizeof(${XINT8_T});
        }

        // Epilogue - tmul with no loads
        _tile_dpbssd (0, 2, 4);
        _tile_dpbssd (1, 3, 5);
      }
    while (k >= 64 * sizeof(int8_t)) {
      _tile_loadd(2, a, a_stride);
      _tile_stream_loadd(4, w, 64);

      // Multiply tiles
      _tile_dpbssd (0, 2, 4);
      $if PREFETCH:
        $for P in range(5120, 6144, 64):
          xnn_prefetch_to_l1((const ${XINT8_T}*) w + ${P});

      a += 64;
      w = (const ${XINT8_T}*) w + 1024;
      k -= 64 * sizeof(${XINT8_T});
    }

    if XNN_UNLIKELY(k != 0) {
      _tile_loadd(6, a, a_stride);
      _tile_stream_loadd(7, w, 64);

      // Multiply tiles
      _tile_dpbssd (0, 6, 7);
      $if PREFETCH:
        $for P in range(5120, 6144, 64):
          xnn_prefetch_to_l1((const ${XINT8_T}*) w + ${P});

      a += kremainder;
      w = (const ${XINT8_T}*) w + kremainder * 16;
      k -= kremainder * sizeof(${XINT8_T});
    }

    // Add tile to bias
    _tile_stored(0, res0, 64);
    _tile_stored(1, res1, 64);
    $if DATATYPE in ["QD8_F16", "QD8_F32", "QC4_F16", "QC4_F32"]:
      $for M in range(MR):
        __m512i vacc${M}x0123456789ABCDEF = _mm512_mullo_epi32(vksum0123456789ABCDEF, _mm512_set1_epi32((int) quantization_params[${M}].zero_point));
      $for M in range(MR):
        vacc${M}x0123456789ABCDEF = _mm512_add_epi32(vacc0x0123456789ABCDEF, _mm512_load_epi32(res0 + ${M * 16}));
    $else:
      $for M in range(MR):
        __m512i vacc${M}x0123456789ABCDEF = _mm512_add_epi32(vksum0123456789ABCDEF, _mm512_load_epi32(res0 + ${M * 16}));
    $if ACCUMULATORS > 1:
      $for M in range(MR):
        vacc${M}x0123456789ABCDEF = _mm512_add_epi32(vacc${M}x0123456789ABCDEF, _mm512_load_epi32(res1 + ${M * 16}));

    $if DATATYPE == "QC4_F32":
      $for M in range(MR):
        vacc${M}x0123456789ABCDEF = _mm512_srai_epi32(vacc${M}x0123456789ABCDEF, 4);
    $for M in range(MR):
      __m512 vscaled${M}x0123456789ABCDEF = _mm512_cvtepi32_ps(vacc${M}x0123456789ABCDEF);

    $if DATATYPE in ["QD8_F32", "QC4_F32"]:
      $for M in range(MR):
        vscaled${M}x0123456789ABCDEF = _mm512_mul_ps(vscaled${M}x0123456789ABCDEF, _mm512_set1_ps(quantization_params[${M}].inv_scale));

      const __m512 vfilter_output_scale0123456789ABCDEF = _mm512_load_ps((const float*) w);
      const __m512 vbias0123456789ABCDEF = _mm512_load_ps((const float*) w + 16);
      w = (const float*) w + 32;

      $for M in range(MR):
        vscaled${M}x0123456789ABCDEF = _mm512_fmadd_ps(vscaled${M}x0123456789ABCDEF, vfilter_output_scale0123456789ABCDEF, vbias0123456789ABCDEF);

      $for M in range(MR):
        vscaled${M}x0123456789ABCDEF = _mm512_max_ps(vscaled${M}x0123456789ABCDEF, voutput_min);

      $for M in range(MR):
        vscaled${M}x0123456789ABCDEF = _mm512_min_ps(vscaled${M}x0123456789ABCDEF, voutput_max);

      if XNN_LIKELY(nc >= 16) {
        $for M in reversed(range(MR)):
          _mm512_storeu_ps(c${M}, vscaled${M}x0123456789ABCDEF);

        $for M in reversed(range(MR)):
          c${M} = (float*) ((uintptr_t) c${M} + cn_stride);

        a -= kc;
        nc -= 16;
      } else {
        // Prepare mask for valid 32-bit elements (depends on nc).
        const __mmask16 vmask = _cvtu32_mask16((UINT32_C(1) << nc) - 1);
        $for M in reversed(range(MR)):
          _mm512_mask_storeu_ps(c${M}, vmask, vscaled${M}x0123456789ABCDEF);
        nc = 0;
      }
    $elif DATATYPE in ["QS8", "QC8"]:
      $if DATATYPE == "QC8":
        const __m512 vscale012345678ABCDEF = _mm512_load_ps(w);
        w = (const float*) w + 16;
        $for M in range(MR):
          vscaled${M}x0123456789ABCDEF = _mm512_mul_ps(vscaled${M}x0123456789ABCDEF, vscale012345678ABCDEF);
      $else:
        $for M in range(MR):
          vscaled${M}x0123456789ABCDEF = _mm512_mul_ps(vscaled${M}x0123456789ABCDEF, vscale);

      $for M in range(MR):
        vscaled${M}x0123456789ABCDEF = _mm512_min_ps(vscaled${M}x0123456789ABCDEF, voutput_max_less_zero_point);

      $for M in range(MR):
        vacc${M}x0123456789ABCDEF = _mm512_cvtps_epi32(vscaled${M}x0123456789ABCDEF);

      $for M in range(MR):
        vacc${M}x0123456789ABCDEF = _mm512_add_epi32(vacc${M}x0123456789ABCDEF, voutput_zero_point);

      $for M in range(MR):
        __m128i vout${M}x0123456789ABCDEF = ${_MM512_CVTXEPI32_EPI8}(vacc${M}x0123456789ABCDEF);

      $for M in range(MR):
        vout${M}x0123456789ABCDEF = ${_MM_MAX_EPX8}(vout${M}x0123456789ABCDEF, voutput_min);

      if (nc >= 16) {
        $for M in reversed(range(MR)):
          _mm_storeu_si128((__m128i*) c${M}, vout${M}x0123456789ABCDEF);
          c${M} = (${OUT_T}*) ((uintptr_t) c${M} + cn_stride);
        a -= kc;
        nc -= 16;
      } else {
        // Prepare mask for valid 8-bit elements (depends on nc).
        const __mmask16 vmask = _cvtu32_mask16((UINT32_C(1) << nc) - UINT32_C(1));

        $for M in reversed(range(MR)):
          _mm_mask_storeu_epi8(c${M}, vmask, vout${M}x0123456789ABCDEF);

        nc = 0;
      }
  } while (nc != 0);
  // Release tile config
  _tile_release();
#endif  // defined(__x86_64__) && defined(__AMX_TILE__)
}
