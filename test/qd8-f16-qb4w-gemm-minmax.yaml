# Copyright 2024 Google LLC
#
# This source code is licensed under the BSD-style license found in the
# LICENSE file in the root directory of this source tree.

# Scalar
- name: xnn_qd8_f16_qb4w_gemm_minmax_ukernel_1x2__scalar
  init: xnn_init_f16_qb4w_minmax_scalar_params
  pack: xnn_pack_qs8_qb4w_gemm_goi_w
  k-block: 32

- name: xnn_qd8_f16_qb4w_gemm_minmax_ukernel_1x4__scalar
  init: xnn_init_f16_qb4w_minmax_scalar_params
  pack: xnn_pack_qs8_qb4w_gemm_goi_w
  k-block: 32

- name: xnn_qd8_f16_qb4w_gemm_minmax_ukernel_1x8__scalar
  init: xnn_init_f16_qb4w_minmax_scalar_params
  pack: xnn_pack_qs8_qb4w_gemm_goi_w
  k-block: 32

- name: xnn_qd8_f16_qb4w_gemm_minmax_ukernel_2x2__scalar
  init: xnn_init_f16_qb4w_minmax_scalar_params
  pack: xnn_pack_qs8_qb4w_gemm_goi_w
  k-block: 32

- name: xnn_qd8_f16_qb4w_gemm_minmax_ukernel_2x4__scalar
  init: xnn_init_f16_qb4w_minmax_scalar_params
  pack: xnn_pack_qs8_qb4w_gemm_goi_w
  k-block: 32

- name: xnn_qd8_f16_qb4w_gemm_minmax_ukernel_2x8__scalar
  init: xnn_init_f16_qb4w_minmax_scalar_params
  pack: xnn_pack_qs8_qb4w_gemm_goi_w
  k-block: 32

- name: xnn_qd8_f16_qb4w_gemm_minmax_ukernel_4x4__scalar
  init: xnn_init_f16_qb4w_minmax_scalar_params
  pack: xnn_pack_qs8_qb4w_gemm_goi_w
  k-block: 32

# ARM NEONDOT
- name: xnn_qd8_f16_qb4w_gemm_minmax_ukernel_1x8c4__neondotfp16arith
  init: xnn_init_f16_qb4w_minmax_scalar_params
  pack: xnn_pack_qs8_qb4w_gemm_goi_w
  k-block: 32
- name: xnn_qd8_f16_qb4w_gemm_minmax_ukernel_1x16c4__neondotfp16arith
  init: xnn_init_f16_qb4w_minmax_scalar_params
  pack: xnn_pack_qs8_qb4w_gemm_goi_w
  k-block: 32
- name: xnn_qd8_f16_qb4w_gemm_minmax_ukernel_2x8c4__neondotfp16arith
  init: xnn_init_f16_qb4w_minmax_scalar_params
  pack: xnn_pack_qs8_qb4w_gemm_goi_w
  k-block: 32
- name: xnn_qd8_f16_qb4w_gemm_minmax_ukernel_2x16c4__neondotfp16arith
  init: xnn_init_f16_qb4w_minmax_scalar_params
  pack: xnn_pack_qs8_qb4w_gemm_goi_w
  k-block: 32
- name: xnn_qd8_f16_qb4w_gemm_minmax_ukernel_3x8c4__neondotfp16arith
  init: xnn_init_f16_qb4w_minmax_scalar_params
  pack: xnn_pack_qs8_qb4w_gemm_goi_w
  k-block: 32
- name: xnn_qd8_f16_qb4w_gemm_minmax_ukernel_3x16c4__neondotfp16arith
  init: xnn_init_f16_qb4w_minmax_scalar_params
  pack: xnn_pack_qs8_qb4w_gemm_goi_w
  k-block: 32
- name: xnn_qd8_f16_qb4w_gemm_minmax_ukernel_4x8c4__neondotfp16arith
  init: xnn_init_f16_qb4w_minmax_scalar_params
  pack: xnn_pack_qs8_qb4w_gemm_goi_w
  k-block: 32
- name: xnn_qd8_f16_qb4w_gemm_minmax_ukernel_4x16c4__neondotfp16arith
  init: xnn_init_f16_qb4w_minmax_scalar_params
  pack: xnn_pack_qs8_qb4w_gemm_goi_w
  k-block: 32
- name: xnn_qd8_f16_qb4w_gemm_minmax_ukernel_5x8c4__neondotfp16arith
  init: xnn_init_f16_qb4w_minmax_scalar_params
  pack: xnn_pack_qs8_qb4w_gemm_goi_w
  k-block: 32
- name: xnn_qd8_f16_qb4w_gemm_minmax_ukernel_5x16c4__neondotfp16arith
  init: xnn_init_f16_qb4w_minmax_scalar_params
  pack: xnn_pack_qs8_qb4w_gemm_goi_w
  k-block: 32
- name: xnn_qd8_f16_qb4w_gemm_minmax_ukernel_6x8c4__neondotfp16arith
  init: xnn_init_f16_qb4w_minmax_scalar_params
  pack: xnn_pack_qs8_qb4w_gemm_goi_w
  k-block: 32
- name: xnn_qd8_f16_qb4w_gemm_minmax_ukernel_6x16c4__neondotfp16arith
  init: xnn_init_f16_qb4w_minmax_scalar_params
  pack: xnn_pack_qs8_qb4w_gemm_goi_w
  k-block: 32

# x86 AVX2
- name: xnn_qd8_f16_qb4w_gemm_minmax_ukernel_1x8c8__avx2
  init: xnn_init_f16_qb4w_minmax_avx_params
  pack: xnn_pack_qs8_qb4w_gemm_goi_w
  k-block: 32

- name: xnn_qd8_f16_qb4w_gemm_minmax_ukernel_2x8c8__avx2
  init: xnn_init_f16_qb4w_minmax_avx_params
  pack: xnn_pack_qs8_qb4w_gemm_goi_w
  k-block: 32

- name: xnn_qd8_f16_qb4w_gemm_minmax_ukernel_3x8c8__avx2
  init: xnn_init_f16_qb4w_minmax_avx_params
  pack: xnn_pack_qs8_qb4w_gemm_goi_w
  k-block: 32

- name: xnn_qd8_f16_qb4w_gemm_minmax_ukernel_4x8c8__avx2
  init: xnn_init_f16_qb4w_minmax_avx_params
  pack: xnn_pack_qs8_qb4w_gemm_goi_w
  k-block: 32

# ARM NEON
- name: xnn_qd8_f16_qb4w_gemm_minmax_ukernel_1x16__neonfp16arith_mlal_lane
  init: xnn_init_f16_qb4w_minmax_scalar_params
  pack: xnn_pack_qs8_qb4w_gemm_goi_w
  k-block: 32

- name: xnn_qd8_f16_qb4w_gemm_minmax_ukernel_2x16__neonfp16arith_mlal_lane
  init: xnn_init_f16_qb4w_minmax_scalar_params
  pack: xnn_pack_qs8_qb4w_gemm_goi_w
  k-block: 32

- name: xnn_qd8_f16_qb4w_gemm_minmax_ukernel_3x16__neonfp16arith_mlal_lane
  init: xnn_init_f16_qb4w_minmax_scalar_params
  pack: xnn_pack_qs8_qb4w_gemm_goi_w
  k-block: 32

- name: xnn_qd8_f16_qb4w_gemm_minmax_ukernel_4x16__neonfp16arith_mlal_lane
  init: xnn_init_f16_qb4w_minmax_scalar_params
  pack: xnn_pack_qs8_qb4w_gemm_goi_w
  k-block: 32

- name: xnn_qd8_f16_qb4w_gemm_minmax_ukernel_6x16__neonfp16arith_mlal_lane
  init: xnn_init_f16_qb4w_minmax_scalar_params
  pack: xnn_pack_qs8_qb4w_gemm_goi_w
  k-block: 32

- name: xnn_qd8_f16_qb4w_gemm_minmax_ukernel_1x16__neonfp16arith_mlal_lane_prfm
  init: xnn_init_f16_qb4w_minmax_scalar_params
  pack: xnn_pack_qs8_qb4w_gemm_goi_w
  k-block: 32

- name: xnn_qd8_f16_qb4w_gemm_minmax_ukernel_2x16__neonfp16arith_mlal_lane_prfm
  init: xnn_init_f16_qb4w_minmax_scalar_params
  pack: xnn_pack_qs8_qb4w_gemm_goi_w
  k-block: 32

- name: xnn_qd8_f16_qb4w_gemm_minmax_ukernel_3x16__neonfp16arith_mlal_lane_prfm
  init: xnn_init_f16_qb4w_minmax_scalar_params
  pack: xnn_pack_qs8_qb4w_gemm_goi_w
  k-block: 32

- name: xnn_qd8_f16_qb4w_gemm_minmax_ukernel_4x16__neonfp16arith_mlal_lane_prfm
  init: xnn_init_f16_qb4w_minmax_scalar_params
  pack: xnn_pack_qs8_qb4w_gemm_goi_w
  k-block: 32

- name: xnn_qd8_f16_qb4w_gemm_minmax_ukernel_6x16__neonfp16arith_mlal_lane_prfm
  init: xnn_init_f16_qb4w_minmax_scalar_params
  pack: xnn_pack_qs8_qb4w_gemm_goi_w
  k-block: 32

# ARM NEONI8MM
- name: xnn_qd8_f16_qb4w_gemm_minmax_ukernel_1x8c8__neoni8mm
  init: xnn_init_f16_qb4w_minmax_scalar_params
  pack: xnn_pack_qs8_qb4w_gemm_goi_w
  k-block: 32
- name: xnn_qd8_f16_qb4w_gemm_minmax_ukernel_1x16c8__neoni8mm
  init: xnn_init_f16_qb4w_minmax_scalar_params
  pack: xnn_pack_qs8_qb4w_gemm_goi_w
  k-block: 32
- name: xnn_qd8_f16_qb4w_gemm_minmax_ukernel_1x32c8__neoni8mm
  init: xnn_init_f16_qb4w_minmax_scalar_params
  pack: xnn_pack_qs8_qb4w_gemm_goi_w
  k-block: 32
- name: xnn_qd8_f16_qb4w_gemm_minmax_ukernel_2x8c8__neoni8mm
  init: xnn_init_f16_qb4w_minmax_scalar_params
  pack: xnn_pack_qs8_qb4w_gemm_goi_w
  k-block: 32
- name: xnn_qd8_f16_qb4w_gemm_minmax_ukernel_2x16c8__neoni8mm
  init: xnn_init_f16_qb4w_minmax_scalar_params
  pack: xnn_pack_qs8_qb4w_gemm_goi_w
  k-block: 32
- name: xnn_qd8_f16_qb4w_gemm_minmax_ukernel_2x32c8__neoni8mm
  init: xnn_init_f16_qb4w_minmax_scalar_params
  pack: xnn_pack_qs8_qb4w_gemm_goi_w
  k-block: 32
- name: xnn_qd8_f16_qb4w_gemm_minmax_ukernel_3x8c8__neoni8mm
  init: xnn_init_f16_qb4w_minmax_scalar_params
  pack: xnn_pack_qs8_qb4w_gemm_goi_w
  k-block: 32
- name: xnn_qd8_f16_qb4w_gemm_minmax_ukernel_3x16c8__neoni8mm
  init: xnn_init_f16_qb4w_minmax_scalar_params
  pack: xnn_pack_qs8_qb4w_gemm_goi_w
  k-block: 32
- name: xnn_qd8_f16_qb4w_gemm_minmax_ukernel_3x32c8__neoni8mm
  init: xnn_init_f16_qb4w_minmax_scalar_params
  pack: xnn_pack_qs8_qb4w_gemm_goi_w
  k-block: 32
- name: xnn_qd8_f16_qb4w_gemm_minmax_ukernel_4x8c8__neoni8mm
  init: xnn_init_f16_qb4w_minmax_scalar_params
  pack: xnn_pack_qs8_qb4w_gemm_goi_w
  k-block: 32
- name: xnn_qd8_f16_qb4w_gemm_minmax_ukernel_4x16c8__neoni8mm
  init: xnn_init_f16_qb4w_minmax_scalar_params
  pack: xnn_pack_qs8_qb4w_gemm_goi_w
  k-block: 32
- name: xnn_qd8_f16_qb4w_gemm_minmax_ukernel_4x32c8__neoni8mm
  init: xnn_init_f16_qb4w_minmax_scalar_params
  pack: xnn_pack_qs8_qb4w_gemm_goi_w
  k-block: 32
- name: xnn_qd8_f16_qb4w_gemm_minmax_ukernel_5x8c8__neoni8mm
  init: xnn_init_f16_qb4w_minmax_scalar_params
  pack: xnn_pack_qs8_qb4w_gemm_goi_w
  k-block: 32
- name: xnn_qd8_f16_qb4w_gemm_minmax_ukernel_5x16c8__neoni8mm
  init: xnn_init_f16_qb4w_minmax_scalar_params
  pack: xnn_pack_qs8_qb4w_gemm_goi_w
  k-block: 32
- name: xnn_qd8_f16_qb4w_gemm_minmax_ukernel_5x32c8__neoni8mm
  init: xnn_init_f16_qb4w_minmax_scalar_params
  pack: xnn_pack_qs8_qb4w_gemm_goi_w
  k-block: 32
- name: xnn_qd8_f16_qb4w_gemm_minmax_ukernel_6x8c8__neoni8mm
  init: xnn_init_f16_qb4w_minmax_scalar_params
  pack: xnn_pack_qs8_qb4w_gemm_goi_w
  k-block: 32
- name: xnn_qd8_f16_qb4w_gemm_minmax_ukernel_6x16c8__neoni8mm
  init: xnn_init_f16_qb4w_minmax_scalar_params
  pack: xnn_pack_qs8_qb4w_gemm_goi_w
  k-block: 32
- name: xnn_qd8_f16_qb4w_gemm_minmax_ukernel_6x32c8__neoni8mm
  init: xnn_init_f16_qb4w_minmax_scalar_params
  pack: xnn_pack_qs8_qb4w_gemm_goi_w
  k-block: 32
- name: xnn_qd8_f16_qb4w_gemm_minmax_ukernel_7x8c8__neoni8mm
  init: xnn_init_f16_qb4w_minmax_scalar_params
  pack: xnn_pack_qs8_qb4w_gemm_goi_w
  k-block: 32
- name: xnn_qd8_f16_qb4w_gemm_minmax_ukernel_7x16c8__neoni8mm
  init: xnn_init_f16_qb4w_minmax_scalar_params
  pack: xnn_pack_qs8_qb4w_gemm_goi_w
  k-block: 32
- name: xnn_qd8_f16_qb4w_gemm_minmax_ukernel_7x32c8__neoni8mm
  init: xnn_init_f16_qb4w_minmax_scalar_params
  pack: xnn_pack_qs8_qb4w_gemm_goi_w
  k-block: 32
- name: xnn_qd8_f16_qb4w_gemm_minmax_ukernel_8x8c8__neoni8mm
  init: xnn_init_f16_qb4w_minmax_scalar_params
  pack: xnn_pack_qs8_qb4w_gemm_goi_w
  k-block: 32
- name: xnn_qd8_f16_qb4w_gemm_minmax_ukernel_8x16c8__neoni8mm
  init: xnn_init_f16_qb4w_minmax_scalar_params
  pack: xnn_pack_qs8_qb4w_gemm_goi_w
  k-block: 32
- name: xnn_qd8_f16_qb4w_gemm_minmax_ukernel_8x32c8__neoni8mm
  init: xnn_init_f16_qb4w_minmax_scalar_params
  pack: xnn_pack_qs8_qb4w_gemm_goi_w
  k-block: 32
